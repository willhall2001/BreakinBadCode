{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install requests\n",
    "# %pip install beautifulsoup4\n",
    "# %pip install selenium\n",
    "# %pip install pandas\n",
    "# %pip install geopy\n",
    "# %pip install geopandas\n",
    "# %pip install folium\n",
    "# %pip install openmeteo-requests\n",
    "# %pip install requests-cache retry-requests numpy pandas\n",
    "# %pip install timezonefinder\n",
    "# % pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import OpenCage\n",
    "from folium import Marker\n",
    "from folium import GeoJson\n",
    "from retry_requests import retry\n",
    "from timezonefinder import TimezoneFinder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Breakdown Section 4\n",
    "---\n",
    "Vintage_Dataframe\n",
    "- grabs two dataframes based on the URLs pulled from the popular producers of the specific wines\n",
    "- one for all the wine vintage data, and one based on popular stats for the wine \n",
    "\n",
    "Final_Vintage_DataFrame \n",
    "- creates a dataframe with vintage data\n",
    "- included here critically is the ratings data tied to the specific producers\n",
    "\n",
    "Converted_Weather_Data\n",
    "- converts output dataframe from All_Weather_Data into a dataframe indexed across producers and years \n",
    "- the columns are monthly averages based on the daily data\n",
    "- adds in the rating and price data for the specific producer of a specific wine for a specific year \n",
    "- final form set up to allow easier training on a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vintage_Dataframe(popular_wines_df):\n",
    "    \"\"\"\n",
    "    Input: takes in a dataframe of popular wines, which includes a column with the URL for each of the wines\n",
    "    Output: two dataframes \n",
    "        Recommended vintages: which has the data on the specific wines chosen \n",
    "        All Vintages: which has data on all the wines\n",
    "    \"\"\"\n",
    "    #Initialize lists to store the extracted data\n",
    "    all_recommended_vintages = []\n",
    "    all_vintages_data = []\n",
    "\n",
    "    #Stips each of the URLs so they are in proper form \n",
    "    popular_wines_df['URL'] = popular_wines_df['URL'].str.split('?').str[0]\n",
    "\n",
    "    #Loop row in the DataFrame\n",
    "    for index, row in popular_wines_df.iterrows():\n",
    "\n",
    "        #Grabs each URL and strips and remaining white space \n",
    "        url = row['URL'].strip() \n",
    "        \n",
    "        try:\n",
    "            r = requests.get(url, headers={\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\"\n",
    "            })\n",
    "\n",
    "            #Check if the request was successful\n",
    "            if r.status_code == 200:\n",
    "                \n",
    "                #Search for the JavaScript data in the page source\n",
    "                res = re.search(r\"window\\.__PRELOADED_STATE__\\.winePageInformation\\s*=\\s*(.*});\", r.text, re.MULTILINE)\n",
    "                \n",
    "                if res:\n",
    "                    data = json.loads(res.group(1))\n",
    "                    \n",
    "                    #Extract recommended vintages\n",
    "                    recommended_vintages = data.get(\"recommended_vintages\", [])\n",
    "                    if recommended_vintages:\n",
    "                        recommended_df = pd.DataFrame(recommended_vintages)\n",
    "\n",
    "                        #Add the URL for reference\n",
    "                        recommended_df['source_url'] = url  \n",
    "                        all_recommended_vintages.append(recommended_df)\n",
    "\n",
    "                    #Extract all vintages\n",
    "                    all_vintages = data.get(\"wine\", {}).get(\"vintages\", [])\n",
    "                    if all_vintages:\n",
    "                        all_vintages_df = pd.DataFrame(all_vintages)\n",
    "\n",
    "                        #Add the URL for reference\n",
    "                        all_vintages_df['source_url'] = url  \n",
    "                        all_vintages_data.append(all_vintages_df)\n",
    "\n",
    "                else:\n",
    "                    print(f\"No data found for URL: {url}\")\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data for URL: {url}, Status code: {r.status_code}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for URL: {url} - {str(e)}\")\n",
    "\n",
    "    #Concats all the recommended vintages and all vintages data into DataFrames\n",
    "    recommended_vintages_df = pd.concat(all_recommended_vintages, ignore_index=True)\n",
    "    all_vintages_df = pd.concat(all_vintages_data, ignore_index=True)\n",
    "   \n",
    "    return recommended_vintages_df, all_vintages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_Vintage_Dataframe(recommended_vintages_df, all_vintages_df, popular_wines_df, lower_date_bound = 1900, lower_rating_bound  = 3, lower_review_count = 1):\n",
    "    \"\"\"\n",
    "    Input: two dataframes \n",
    "        Recommended vintages: which has the data on the specific wines chosen \n",
    "        All Vintages: which has data on all the wines\n",
    "    Output:  one dataframe \n",
    "        all_filtered_winebottle: dataframe with vintage dataframe, of importance is the rating, price, year and producer name\n",
    "    \"\"\"\n",
    "\n",
    "    #Defines a function for internal function use that grabs key-values pairs\n",
    "    def extract_object_data(Object_data):\n",
    "        \"\"\"\n",
    "        Extracts key-value pairs from an object and returns a Series\n",
    "        \"\"\"\n",
    "        if isinstance(Object_data, dict):\n",
    "            return pd.Series(Object_data)\n",
    "        else:\n",
    "            return pd.Series()  \n",
    "\n",
    "    #Filters the vintages df so that the all the data is only gotten for those with a valid rating \n",
    "    all_vintages_df_True = all_vintages_df[all_vintages_df[\"has_valid_ratings\"] == True]\n",
    "\n",
    "    #Apply the function to the 'object_column' and create a new DataFrame\n",
    "    new_columns = all_vintages_df_True['statistics'].apply(extract_object_data)\n",
    "\n",
    "    #Concatenate the original DataFrame with the new columns\n",
    "    all_vintages_df_True = pd.concat([all_vintages_df_True, new_columns], axis=1)\n",
    "\n",
    "    #Grabs specific volumns from the vintage data \n",
    "    df4 = all_vintages_df_True[['id', 'name', 'year', 'ratings_average', 'reviews_count']]\n",
    "\n",
    "    #Grabs the id and amount from the vintage data then creates a new dataframe \n",
    "    recommended_vintages_df['id'] =recommended_vintages_df['vintage'].apply(lambda x: x.get('id'))\n",
    "    df5 =recommended_vintages_df[['id', 'type']].drop_duplicates(subset = ['id'])\n",
    "    \n",
    "    #Merges the two dataframes\n",
    "    final_merge_df = pd.merge(df4, df5, on='id', how='left')\n",
    "\n",
    "    #Filters the data by year, ratings average and reviews count \n",
    "    all_filtered_winebottle = final_merge_df[\n",
    "        (final_merge_df['year'] >= lower_date_bound) &\n",
    "        (final_merge_df['ratings_average'] > lower_rating_bound) &\n",
    "        (final_merge_df['reviews_count'] > lower_review_count)\n",
    "    ]\n",
    "\n",
    "    #Change the columns names \n",
    "    all_filtered_winebottle = all_filtered_winebottle.rename(columns={'id': 'ID',\n",
    "                                                                      'name': 'Producer_v',\n",
    "                                                                      'year': 'Year_v',\n",
    "                                                                      'ratings_average': 'Ratings Average',\n",
    "                                                                      'reviews_count': 'Reviews Count',\n",
    "                                                                      'type': 'Type',\n",
    "                                                                      })\n",
    "    \n",
    "    def producer_name(row, popular_wines):\n",
    "        \"\"\"\n",
    "        Checks if a row is in the list of producers, and returns the producer name \n",
    "        \"\"\"\n",
    "        list_of_producers = popular_wines['Producer'].unique()\n",
    "\n",
    "        for producer in list_of_producers:\n",
    "\n",
    "            lower_producer = producer.lower()\n",
    "            lower_row = row.lower()\n",
    "\n",
    "            if lower_producer in lower_row:\n",
    "\n",
    "                return producer\n",
    "            \n",
    "        return row\n",
    "    \n",
    "    #Goes through the names column and changes the name to the producer name, to allow for later merging between dataframes\n",
    "    all_filtered_winebottle['Producer_v'] = all_filtered_winebottle['Producer_v'].apply(lambda row: producer_name(row, popular_wines_df))\n",
    "\n",
    "    #Add a producer/year column for future merging \n",
    "    all_filtered_winebottle['Producer/Year'] = all_filtered_winebottle.apply(lambda row: row['Producer_v'] + ' ' + str(row['Year_v']), axis=1)\n",
    "\n",
    "    return all_filtered_winebottle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Data(weather_df, vintage_df):\n",
    "    \"\"\"\n",
    "    Input: Weather dataframe indexed on the daily scale,\n",
    "        Vintage dataframe which has yearly bottles from the same producer and wine type\n",
    "    Output: Weather dataframe indexed based on a single row for a producer and year \n",
    "        columns will be monthly min, max or average for the respective data per year\n",
    "    \"\"\"\n",
    "    #Weather_df.index = pd.to_datetime(weather_df.index)\n",
    "    producers = weather_df['Producer'].unique()\n",
    "\n",
    "    #Initializes a dataframe \n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    #Check to see if date is the index\n",
    "    if type(weather_df.index[0]) == int:\n",
    "\n",
    "        weather_df = weather_df.set_index('Date') \n",
    "\n",
    "    #Create a column for the year and produce all the unique years\n",
    "    weather_df.index = pd.to_datetime(weather_df.index)\n",
    "    weather_df['Year'] = weather_df.index.year\n",
    "    unique_years = weather_df['Year'].unique()\n",
    "\n",
    "    #Find all the unique months\n",
    "    weather_df['Month'] = weather_df.index.month\n",
    "    unique_months = weather_df['Month'].unique()\n",
    "\n",
    "    #Gives key for the month names \n",
    "    month_names = {1 : 'January', 2 : 'February', 3 : 'March', 4 : 'April', 5 : 'May', \n",
    "                                  6 : 'June', 7 : 'July', 8 : 'August', 9 : 'September', 10 : 'October', 11 : 'November',\n",
    "                                  12 : 'December'}\n",
    "\n",
    "    for producer in producers:\n",
    "\n",
    "        #Filter the data based on the producer\n",
    "        producer_df = weather_df[weather_df['Producer'] == producer]\n",
    "\n",
    "        #Iterate over each unique year\n",
    "        for year in unique_years:\n",
    "            \n",
    "            #Filter the data for the specific year\n",
    "            yearly_df = producer_df[producer_df['Year'] == year]\n",
    "\n",
    "            #Creates initial data\n",
    "            yearly_data = {'Producer' : producer, 'Year' : year}\n",
    "\n",
    "            #Ierate over each unique month\n",
    "            for month in unique_months: \n",
    "\n",
    "                #Filter the data for the specific month\n",
    "                monthly_df = yearly_df[yearly_df['Month'] == month]\n",
    "\n",
    "                #Group by month\n",
    "                Grouped_Daily_into_Monthly = monthly_df.groupby(monthly_df.index.to_period('M'))\n",
    "\n",
    "                #Change month number to month name\n",
    "                month = month_names[month]\n",
    "\n",
    "                yearly_data.update({\n",
    "                    \n",
    "                    'WineType' : Grouped_Daily_into_Monthly['Top WineType'].first()[0],\n",
    "                    f'{month} Max Temp (°C)' : Grouped_Daily_into_Monthly['Max Temp (°C)'].max().iloc[0],\n",
    "                    f'{month} Min Temp (°C)' : Grouped_Daily_into_Monthly['Min Temp (°C)'].min().iloc[0],\n",
    "                    f'{month} Avg Temp (°C)' : Grouped_Daily_into_Monthly['Avg Temp (°C)'].mean().iloc[0],\n",
    "                    f'{month} Max Relative Humidity' : Grouped_Daily_into_Monthly['Max Relative Humidity'].max().iloc[0],\n",
    "                    f'{month} Min Relative Humidity' : Grouped_Daily_into_Monthly['Min Relative Humidity'].min().iloc[0],\n",
    "                    f'{month} Avg Relative Humidity' : Grouped_Daily_into_Monthly['Max Relative Humidity'].mean().iloc[0],\n",
    "                    f'{month} Cumulative Rain (mm)' : Grouped_Daily_into_Monthly['Cumulative Rain (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Snow (mm)' : Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Precip (mm)' : Grouped_Daily_into_Monthly['Cumulative Rain (mm)'].sum().iloc[0] + Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Snow (mm)' : Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Avg Cloud Cover (%)' : Grouped_Daily_into_Monthly['Avg Cloud Cover (%)'].mean().iloc[0],\n",
    "                    f'{month} Max Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Max Wind Speed (Km/h)'].max().iloc[0],\n",
    "                    f'{month} Min Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Min Wind Speed (Km/h)'].min().iloc[0],\n",
    "                    f'{month} Avg Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Avg Wind Speed (Km/h)'].mean().iloc[0],\n",
    "                    f'{month} Avg Daylight Hours' : Grouped_Daily_into_Monthly['Daylight Hours'].mean().iloc[0] \n",
    "\n",
    "                })\n",
    "            \n",
    "            #Adds this yearly data to original df\n",
    "            final_df = pd.concat([final_df, pd.DataFrame([yearly_data])], ignore_index=True)\n",
    "    \n",
    "    #Add a producer/year column for future merging and reset index\n",
    "    final_df = final_df.reset_index()\n",
    "    final_df['Producer/Year'] = final_df.apply(lambda row: row['Producer'] + ' ' + str(row['Year']), axis=1)\n",
    "\n",
    "    #Combine the two dataframes\n",
    "    final_df = pd.merge(final_df, vintage_df, on = 'Producer/Year', how = 'left')\n",
    "\n",
    "    #Modify the dataframe for easier viewing\n",
    "    final_df = final_df.drop(columns = ['index','Producer/Year', 'ID', 'Reviews Count', 'Producer_v', 'Year_v'])\n",
    "    final_df.insert(0, 'Producer', final_df.pop('Producer'))\n",
    "    final_df.insert(1, 'Year', final_df.pop('Year'))\n",
    "    final_df.insert(2, 'Ratings Average', final_df.pop('Ratings Average'))\n",
    "\n",
    "    #Drop all the rows that have NAN in the ratings average column \n",
    "    final_df = final_df.dropna(subset = ['Ratings Average'])\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Section 4 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df_final = pd.read_csv(r'C:\\Users\\fwhal\\Downloads\\CME528\\Project\\BreakinBadCode\\Final_DataFrames\\FINAL_wine_df_FINAL.csv', index = True)\n",
    "\n",
    "recommended_vintages_df, all_vintages_df = Vintage_Dataframe(pd.read_csv(r'C:\\Users\\fwhal\\Downloads\\CME528\\Project\\Final_DataFrames\\FINAL_wine_df_filtered_FINAL.csv'))\n",
    "vintage_df_final = Final_Vintage_Dataframe(recommended_vintages_df, all_vintages_df, wine_df_final, lower_date_bound = 1900, lower_rating_bound  = 3, lower_review_count = 1)\n",
    "FINAL_training_data_FINAL = Training_Data(pd.read_csv(r'C:\\Users\\fwhal\\Downloads\\CME528\\Project\\Final_DataFrames\\FINAL_weather_data_FINAL.csv'), vintage_df_final)\n",
    "FINAL_training_data_FINAL.to_csv(r'C:\\Users\\fwhal\\Downloads\\CME528\\Project\\Final_DataFrames\\FINAL_training_data_FINAL.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
