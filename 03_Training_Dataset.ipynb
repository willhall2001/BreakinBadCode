{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install requests\n",
    "# %pip install beautifulsoup4\n",
    "# %pip install selenium\n",
    "# %pip install pandas\n",
    "# %pip install geopy\n",
    "# %pip install geopandas\n",
    "# %pip install folium\n",
    "# %pip install openmeteo-requests\n",
    "# %pip install requests-cache retry-requests numpy pandas\n",
    "# %pip install timezonefinder\n",
    "# % pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import OpenCage\n",
    "from folium import Marker\n",
    "from folium import GeoJson\n",
    "from retry_requests import retry\n",
    "from timezonefinder import TimezoneFinder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Breakdown Section 4\n",
    "---\n",
    "Vintage_Dataframe\n",
    "- grabs two dataframes based on the URLs pulled from the popular producers of the specific wines\n",
    "- one for all the wine vintage data, and one based on popular stats for the wine \n",
    "\n",
    "Final_Vintage_DataFrame \n",
    "- creates a dataframe with vintage data\n",
    "- included here critically is the ratings data tied to the specific producers\n",
    "\n",
    "Converted_Weather_Data\n",
    "- converts output dataframe from All_Weather_Data into a dataframe indexed across producers and years \n",
    "- the columns are monthly averages based on the daily data\n",
    "- adds in the rating and price data for the specific producer of a specific wine for a specific year \n",
    "- final form set up to allow easier training on a model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Vintage_Dataframe(popular_wines_df):\n",
    "    \"\"\"\n",
    "    Input: takes in a dataframe of popular wines, which includes a column with the URL for each of the wines\n",
    "    Output: two dataframes \n",
    "        Recommended vintages: which has the data on the specific wines chosen \n",
    "        All Vintages: which has data on all the wines\n",
    "    \"\"\"\n",
    "    #Initialize lists to store the extracted data\n",
    "    all_recommended_vintages = []\n",
    "    all_vintages_data = []\n",
    "\n",
    "    #Stips each of the URLs so they are in proper form \n",
    "    popular_wines_df['URL'] = popular_wines_df['URL'].str.split('?').str[0]\n",
    "\n",
    "    #Loop row in the DataFrame\n",
    "    for index, row in popular_wines_df.iterrows():\n",
    "\n",
    "        #Grabs each URL and strips and remaining white space \n",
    "        url = row['URL'].strip() \n",
    "        \n",
    "        try:\n",
    "            r = requests.get(url, headers={\n",
    "                \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64; rv:66.0) Gecko/20100101 Firefox/66.0\"\n",
    "            })\n",
    "\n",
    "            #Check if the request was successful\n",
    "            if r.status_code == 200:\n",
    "                \n",
    "                #Search for the JavaScript data in the page source\n",
    "                res = re.search(r\"window\\.__PRELOADED_STATE__\\.winePageInformation\\s*=\\s*(.*});\", r.text, re.MULTILINE)\n",
    "                \n",
    "                if res:\n",
    "                    data = json.loads(res.group(1))\n",
    "                    \n",
    "                    #Extract recommended vintages\n",
    "                    recommended_vintages = data.get(\"recommended_vintages\", [])\n",
    "                    if recommended_vintages:\n",
    "                        recommended_df = pd.DataFrame(recommended_vintages)\n",
    "\n",
    "                        #Add the URL for reference\n",
    "                        recommended_df['source_url'] = url  \n",
    "                        all_recommended_vintages.append(recommended_df)\n",
    "\n",
    "                    #Extract all vintages\n",
    "                    all_vintages = data.get(\"wine\", {}).get(\"vintages\", [])\n",
    "                    if all_vintages:\n",
    "                        all_vintages_df = pd.DataFrame(all_vintages)\n",
    "\n",
    "                        #Add the URL for reference\n",
    "                        all_vintages_df['source_url'] = url  \n",
    "                        all_vintages_data.append(all_vintages_df)\n",
    "\n",
    "                else:\n",
    "                    print(f\"No data found for URL: {url}\")\n",
    "            else:\n",
    "                print(f\"Failed to retrieve data for URL: {url}, Status code: {r.status_code}\")\n",
    "        \n",
    "        except Exception as e:\n",
    "            print(f\"An error occurred for URL: {url} - {str(e)}\")\n",
    "\n",
    "    #Concats all the recommended vintages and all vintages data into DataFrames\n",
    "    recommended_vintages_df = pd.concat(all_recommended_vintages, ignore_index=True)\n",
    "    all_vintages_df = pd.concat(all_vintages_data, ignore_index=True)\n",
    "   \n",
    "    return recommended_vintages_df, all_vintages_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_Vintage_Dataframe(recommended_vintages_df, all_vintages_df, popular_wines_df, lower_date_bound = 1900, lower_rating_bound  = 3, lower_review_count = 1):\n",
    "    \"\"\"\n",
    "    Input: two dataframes \n",
    "        Recommended vintages: which has the data on the specific wines chosen \n",
    "        All Vintages: which has data on all the wines\n",
    "    Output:  one dataframe \n",
    "        all_filtered_winebottle: dataframe with vintage dataframe, of importance is the rating, price, year and producer name\n",
    "    \"\"\"\n",
    "\n",
    "    #Defines a function for internal function use that grabs key-values pairs\n",
    "    def extract_object_data(Object_data):\n",
    "        \"\"\"\n",
    "        Extracts key-value pairs from an object and returns a Series\n",
    "        \"\"\"\n",
    "        if isinstance(Object_data, dict):\n",
    "            return pd.Series(Object_data)\n",
    "        else:\n",
    "            return pd.Series()  \n",
    "\n",
    "    #Filters the vintages df so that the all the data is only gotten for those with a valid rating \n",
    "    all_vintages_df_True = all_vintages_df[all_vintages_df[\"has_valid_ratings\"] == True]\n",
    "\n",
    "    #Apply the function to the 'object_column' and create a new DataFrame\n",
    "    new_columns = all_vintages_df_True['statistics'].apply(extract_object_data)\n",
    "\n",
    "    #Concatenate the original DataFrame with the new columns\n",
    "    all_vintages_df_True = pd.concat([all_vintages_df_True, new_columns], axis=1)\n",
    "    \n",
    "    #Grabs specific volumns from the vintage data \n",
    "    df4 = all_vintages_df_True[['id', 'name', 'year', 'ratings_average', 'reviews_count']]\n",
    "\n",
    "    #Grabs the id and amount from the vintage data then creates a new dataframe \n",
    "    recommended_vintages_df['id'] =recommended_vintages_df['vintage'].apply(lambda x: x.get('id'))\n",
    "    df5 =recommended_vintages_df[['id', 'type']].drop_duplicates(subset = ['id'])\n",
    "    \n",
    "    #Merges the two dataframes\n",
    "    final_merge_df = pd.merge(df4, df5, on='id', how='left')\n",
    "\n",
    "    #Filters the data by year, ratings average and reviews count \n",
    "    all_filtered_winebottle = final_merge_df[\n",
    "        (final_merge_df['year'] >= lower_date_bound) &\n",
    "        (final_merge_df['ratings_average'] > lower_rating_bound) &\n",
    "        (final_merge_df['reviews_count'] > lower_review_count)\n",
    "    ]\n",
    "\n",
    "    #Change the columns names \n",
    "    all_filtered_winebottle = all_filtered_winebottle.rename(columns={'id': 'ID',\n",
    "                                                                      'name': 'Producer_v',\n",
    "                                                                      'year': 'Year_v',\n",
    "                                                                      'ratings_average': 'Ratings Average',\n",
    "                                                                      'reviews_count': 'Reviews Count',\n",
    "                                                                      'type': 'Type',\n",
    "                                                                      })\n",
    "    \n",
    "    def producer_name(row, popular_wines):\n",
    "        \"\"\"\n",
    "        Checks if a row is in the list of producers, and returns the producer name \n",
    "        \"\"\"\n",
    "        list_of_producers = popular_wines['Producer'].unique()\n",
    "\n",
    "        for producer in list_of_producers:\n",
    "\n",
    "            lower_producer = producer.lower()\n",
    "            lower_row = row.lower()\n",
    "\n",
    "            if lower_producer in lower_row:\n",
    "\n",
    "                return producer\n",
    "            \n",
    "        return row\n",
    "    \n",
    "\n",
    "    def wine_type(row, popular_wines):\n",
    "        \"\"\"\n",
    "        Checks if a row is in the list of wines, and returns the WineType \n",
    "        \"\"\"\n",
    "        list_of_wines = popular_wines['WineType'].unique().tolist()\n",
    "\n",
    "        list_of_wines.append(['château margaux', 'cabernet sauvignon', 'pinot noir', 'zinfandel', 'syrah', \n",
    "                            'pinot gris', 'sauvignon blanc', 'chardonnay', 'baco noir', 'bordeaux',\n",
    "                            'malbec', 'chardonnay', 'pinot grigio', 'merlot', 'sangiovese', 'shiraz',\n",
    "                            'cabernet franc', 'muscat', 'grenache', 'sangiovese'])\n",
    "        \n",
    "        for wine in list_of_wines:\n",
    "           \n",
    "            lower_wine = wine.lower()\n",
    "            lower_row = row.lower()\n",
    "\n",
    "            if lower_wine in lower_row:\n",
    "\n",
    "                return lower_wine\n",
    "            \n",
    "        return row\n",
    "    \n",
    "    # return all_filtered_winebottle['Producer_v']\n",
    "    #Goes through the names column and changes the name to the producer name, to allow for later merging between dataframes\n",
    "    all_filtered_winebottle['WineType'] = all_filtered_winebottle['Producer_v'].apply(lambda row: wine_type(row, popular_wines_df))\n",
    "    all_filtered_winebottle['Producer_v'] = all_filtered_winebottle['Producer_v'].apply(lambda row: producer_name(row, popular_wines_df))\n",
    "\n",
    "    #Add a producer/year column for future merging \n",
    "    all_filtered_winebottle['Producer/Year'] = all_filtered_winebottle.apply(lambda row: row['Producer_v'] + ' ' + str(row['Year_v']), axis=1)\n",
    "\n",
    "    return all_filtered_winebottle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Data(weather_df, vintage_df):\n",
    "    \"\"\"\n",
    "    Input: Weather dataframe indexed on the daily scale,\n",
    "        Vintage dataframe which has yearly bottles from the same producer and wine type\n",
    "    Output: Weather dataframe indexed based on a single row for a producer and year \n",
    "        columns will be monthly min, max or average for the respective data per year\n",
    "    \"\"\"\n",
    "    #Weather_df.index = pd.to_datetime(weather_df.index)\n",
    "    producers = weather_df['Producer'].unique()\n",
    "\n",
    "    #Initializes a dataframe \n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    #Check to see if date is the index\n",
    "    if type(weather_df.index[0]) == int:\n",
    "\n",
    "        weather_df = weather_df.set_index('Date') \n",
    "\n",
    "    #Create a column for the year and produce all the unique years\n",
    "    weather_df.index = pd.to_datetime(weather_df.index)\n",
    "    weather_df['Year'] = weather_df.index.year\n",
    "    unique_years = weather_df['Year'].unique()\n",
    "\n",
    "    #Find all the unique months\n",
    "    weather_df['Month'] = weather_df.index.month\n",
    "    unique_months = weather_df['Month'].unique()\n",
    "\n",
    "    #Gives key for the month names \n",
    "    month_names = {1 : 'January', 2 : 'February', 3 : 'March', 4 : 'April', 5 : 'May', \n",
    "                                  6 : 'June', 7 : 'July', 8 : 'August', 9 : 'September', 10 : 'October', 11 : 'November',\n",
    "                                  12 : 'December'}\n",
    "\n",
    "    for producer in producers:\n",
    "\n",
    "        #Filter the data based on the producer\n",
    "        producer_df = weather_df[weather_df['Producer'] == producer]\n",
    "\n",
    "        #Iterate over each unique year\n",
    "        for year in unique_years:\n",
    "            \n",
    "            #Filter the data for the specific year\n",
    "            yearly_df = producer_df[producer_df['Year'] == year]\n",
    "\n",
    "            #Creates initial data\n",
    "            yearly_data = {'Producer' : producer, 'Year' : year}\n",
    "\n",
    "            #Ierate over each unique month\n",
    "            for month in unique_months: \n",
    "\n",
    "                #Filter the data for the specific month\n",
    "                monthly_df = yearly_df[yearly_df['Month'] == month]\n",
    "\n",
    "                #Group by month\n",
    "                Grouped_Daily_into_Monthly = monthly_df.groupby(monthly_df.index.to_period('M'))\n",
    "\n",
    "                #Change month number to month name\n",
    "                month = month_names[month]\n",
    "\n",
    "                #Add in data around extreme temperature conditions\n",
    "                days_below_0 = Grouped_Daily_into_Monthly['Avg Temp (°C)'].apply(lambda row: (row <= 0).sum())\n",
    "                days_above_0 = Grouped_Daily_into_Monthly['Avg Temp (°C)'].apply(lambda row: (row >= 0).sum())\n",
    "\n",
    "                yearly_data.update({\n",
    "                    \n",
    "                    'WineType' : Grouped_Daily_into_Monthly['Top WineType'].first()[0],\n",
    "                    'District' : Grouped_Daily_into_Monthly['Top District'].first()[0],\n",
    "                    f'{month} Max Temp (°C)' : Grouped_Daily_into_Monthly['Max Temp (°C)'].max().iloc[0],\n",
    "                    f'{month} Min Temp (°C)' : Grouped_Daily_into_Monthly['Min Temp (°C)'].min().iloc[0],\n",
    "                    f'{month} Avg Temp (°C)' : Grouped_Daily_into_Monthly['Avg Temp (°C)'].mean().iloc[0],\n",
    "                    f'{month} Max Relative Humidity' : Grouped_Daily_into_Monthly['Max Relative Humidity'].max().iloc[0],\n",
    "                    f'{month} Min Relative Humidity' : Grouped_Daily_into_Monthly['Min Relative Humidity'].min().iloc[0],\n",
    "                    f'{month} Avg Relative Humidity' : Grouped_Daily_into_Monthly['Max Relative Humidity'].mean().iloc[0],\n",
    "                    f'{month} Cumulative Rain (mm)' : Grouped_Daily_into_Monthly['Cumulative Rain (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Snow (mm)' : Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Precip (mm)' : Grouped_Daily_into_Monthly['Cumulative Rain (mm)'].sum().iloc[0] + Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Snow (mm)' : Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Avg Cloud Cover (%)' : Grouped_Daily_into_Monthly['Avg Cloud Cover (%)'].mean().iloc[0],\n",
    "                    f'{month} Max Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Max Wind Speed (Km/h)'].max().iloc[0],\n",
    "                    f'{month} Min Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Min Wind Speed (Km/h)'].min().iloc[0],\n",
    "                    f'{month} Avg Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Avg Wind Speed (Km/h)'].mean().iloc[0],\n",
    "                    f'{month} Avg Daylight Hours' : Grouped_Daily_into_Monthly['Daylight Hours'].mean().iloc[0], \n",
    "                    f'{month} Days Below 0 (°C)': days_below_0.iloc[0],\n",
    "                    f'{month} Days Above 32 (°C)': days_above_0.iloc[0]\n",
    "\n",
    "                })\n",
    "            \n",
    "            #Adds this yearly data to original df\n",
    "            final_df = pd.concat([final_df, pd.DataFrame([yearly_data])], ignore_index=True)\n",
    "    \n",
    "    #Add a producer/year column for future merging and reset index\n",
    "    final_df = final_df.reset_index()\n",
    "    final_df['Producer/Year'] = final_df.apply(lambda row: row['Producer'] + ' ' + str(row['Year']), axis=1)\n",
    "    weather_df_columns = final_df.drop(columns = ['index'])\n",
    "\n",
    "    #Combine the two dataframes\n",
    "    final_df = pd.merge(final_df, vintage_df, on = 'Producer/Year', how = 'left')\n",
    "\n",
    "    #Modify the dataframe for easier viewing\n",
    "    final_df = final_df.drop(columns = ['index','Producer/Year', 'ID', 'Reviews Count', 'Producer_v', 'Year_v'])\n",
    "    final_df.insert(0, 'Producer', final_df.pop('Producer'))\n",
    "    final_df.insert(1, 'District', final_df.pop('District'))\n",
    "    final_df.insert(2, 'Year', final_df.pop('Year'))\n",
    "    final_df.insert(3, 'Ratings Average', final_df.pop('Ratings Average'))\n",
    "\n",
    "    #Drop all the rows that have NAN in the ratings average column \n",
    "    final_df = final_df.dropna(subset = ['Ratings Average'])\n",
    "\n",
    "    return final_df, weather_df_columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Data_Model2(formatted_weather_data, vintage_df_M2, all_bottle_data):\n",
    "    \"\"\"\n",
    "    Input: Weather data for each district, all the vintage data for each bottle, all the bottles of interest\n",
    "\n",
    "    Function converts, merges and formats the three dataframes into one final training dataframe \n",
    "\n",
    "    Output: 1 dataframe where each bottle has a rating, price, and weather data for each bottle\n",
    "        Weather data is for the district, so each bottle will have the same weather data within a district\n",
    "        Creating this dataframe to show local trends based on vintage qualitative data\n",
    "\n",
    "    \"\"\"\n",
    "    vintage_df_M2['Producer/WineType'] = (vintage_df_M2['Producer_v'] + '/' +  vintage_df_M2['WineType']).str.lower().str.strip()\n",
    "    all_bottle_data['Producer/WineType'] = (all_bottle_data['Producer'] + '/' +  all_bottle_data['WineType']).str.lower().str.strip()\n",
    "\n",
    "    vintage_df_M2 = vintage_df_M2.drop(columns = ['Producer_v', 'WineType'])\n",
    "    all_bottle_data = all_bottle_data.drop(columns = ['Producer', 'WineType'])\n",
    "\n",
    "    district_df = all_bottle_data[['Producer/WineType', 'Top District', 'Price']]\n",
    "\n",
    "    int_df = pd.merge(district_df, vintage_df_M2 on = 'Producer/WineType')\n",
    "    \n",
    "    final_df = pd.DataFrame()\n",
    "    final_df[['Producer/WineType', 'District', 'Year', 'Ratings Average', 'Price', 'Type']] = int_df[['Producer/WineType', 'Top District', 'Year_v', 'Ratings Average', 'Price', 'Type']]\n",
    "\n",
    "    final_df[['Producer', 'WineType']] = final_df['Producer/WineType'].str.split('/', expand = True)\n",
    "    final_df['District/Year'] = (final_df['District'] + '/' + final_df['Year'].astype(str)).str.lower().str.strip()\n",
    "    \n",
    "    formatted_weather_data['District/Year'] = (formatted_weather_data['District'] + '/' + formatted_weather_data['Year'].astype(str)).str.lower().str.strip()\n",
    "    formatted_weather_data = formatted_weather_data.drop(columns = ['Producer', 'Year', 'WineType', 'District'])\n",
    "\n",
    "    final_df_M2 = pd.merge(final_df, formatted_weather_data, on = 'District/Year', how = 'left')  \n",
    "    final_df_M2 = final_df_M2.drop(columns = ['Producer/Year', 'District/Year', 'Producer/WineType', ])\n",
    "\n",
    "    final_df_M2.insert(0, 'Producer', final_df_M2.pop('Producer'))\n",
    "    final_df_M2.insert(1, 'WineType', final_df_M2.pop('WineType'))\n",
    "    final_df_M2.insert(2, 'District', final_df_M2.pop('District'))\n",
    "    final_df_M2.insert(3, 'Year', final_df_M2.pop('Year'))\n",
    "\n",
    "    return final_df_M2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variable Section 4 \n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_df_file_path = r'C:\\Users\\fwhal\\Downloads\\CME528\\Project\\Repo-2\\BreakinBadCode\\Final_DataFrames'\n",
    "\n",
    "FINAL_wine_df_FINAL = pd.read_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_FINAL.csv'))\n",
    "FINAL_weather_data_FINAL = pd.read_csv(os.path.join(final_df_file_path, 'FINAL_weather_data_FINAL.csv'))\n",
    "FINAL_wine_df_filtered_1Bottle_FINAL = pd.read_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_filtered_1Bottle_FINAL.csv'))\n",
    "FINAL_wine_df_filtered_All_Bottles_FINAL = pd.read_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_filtered_All_Bottles_FINAL.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\fwhal\\AppData\\Local\\Temp\\ipykernel_8096\\657629713.py:54: UserWarning: Converting to PeriodArray/Index representation will drop timezone information.\n",
      "  Grouped_Daily_into_Monthly = monthly_df.groupby(monthly_df.index.to_period('M'))\n",
      "C:\\Users\\fwhal\\AppData\\Local\\Temp\\ipykernel_8096\\657629713.py:61: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'WineType' : Grouped_Daily_into_Monthly['Top WineType'].first()[0],\n",
      "C:\\Users\\fwhal\\AppData\\Local\\Temp\\ipykernel_8096\\657629713.py:62: FutureWarning: Series.__getitem__ treating keys as positions is deprecated. In a future version, integer keys will always be treated as labels (consistent with DataFrame behavior). To access a value by position, use `ser.iloc[pos]`\n",
      "  'District' : Grouped_Daily_into_Monthly['Top District'].first()[0],\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "'<' not supported between instances of 'SeriesGroupBy' and 'int'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[145], line 4\u001b[0m\n\u001b[0;32m      1\u001b[0m recommended_vintages_M1_df, all_vintages_M1_df \u001b[38;5;241m=\u001b[39m Vintage_Dataframe(FINAL_wine_df_filtered_1Bottle_FINAL)\n\u001b[0;32m      2\u001b[0m vintage_df_M1_final \u001b[38;5;241m=\u001b[39m Final_Vintage_Dataframe(recommended_vintages_M1_df, all_vintages_M1_df, FINAL_wine_df_FINAL, lower_date_bound \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m2000\u001b[39m, lower_rating_bound  \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m3\u001b[39m, lower_review_count \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m)\n\u001b[1;32m----> 4\u001b[0m FINAL_training_data_Model1_FINAL, Columned_Weather_Data \u001b[38;5;241m=\u001b[39m Training_Data(FINAL_weather_data_FINAL, vintage_df_M1_final)\n\u001b[0;32m      5\u001b[0m FINAL_training_data_Model1_FINAL\u001b[38;5;241m.\u001b[39mto_csv(os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(final_df_file_path, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mFINAL_training_data_Model1_FINAL.csv\u001b[39m\u001b[38;5;124m'\u001b[39m), index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[144], line 78\u001b[0m, in \u001b[0;36mTraining_Data\u001b[1;34m(weather_df, vintage_df)\u001b[0m\n\u001b[0;32m     56\u001b[0m     \u001b[38;5;66;03m#Change month number to month name\u001b[39;00m\n\u001b[0;32m     57\u001b[0m     month \u001b[38;5;241m=\u001b[39m month_names[month]\n\u001b[0;32m     59\u001b[0m     yearly_data\u001b[38;5;241m.\u001b[39mupdate({\n\u001b[0;32m     60\u001b[0m         \n\u001b[0;32m     61\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWineType\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop WineType\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfirst()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     62\u001b[0m         \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDistrict\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTop District\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mfirst()[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     63\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Max Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     64\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Min Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     65\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Avg Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     66\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Max Relative Humidity\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Relative Humidity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     67\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Min Relative Humidity\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin Relative Humidity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     68\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Avg Relative Humidity\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Relative Humidity\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     69\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Cumulative Rain (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Rain (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     70\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Cumulative Snow (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Snow (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     71\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Cumulative Precip (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Rain (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m] \u001b[38;5;241m+\u001b[39m Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Snow (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     72\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Cumulative Snow (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mCumulative Snow (mm)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39msum()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     73\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Avg Cloud Cover (%)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Cloud Cover (\u001b[39m\u001b[38;5;124m%\u001b[39m\u001b[38;5;124m)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     74\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Max Wind Speed (Km/h)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMax Wind Speed (Km/h)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmax()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     75\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Min Wind Speed (Km/h)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMin Wind Speed (Km/h)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmin()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     76\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Avg Wind Speed (Km/h)\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Wind Speed (Km/h)\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m],\n\u001b[0;32m     77\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Avg Daylight Hours\u001b[39m\u001b[38;5;124m'\u001b[39m : Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mDaylight Hours\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmean()\u001b[38;5;241m.\u001b[39miloc[\u001b[38;5;241m0\u001b[39m], \n\u001b[1;32m---> 78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Days Below 0 (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m: (Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m<\u001b[39m \u001b[38;5;241m0\u001b[39m)\u001b[38;5;241m.\u001b[39msum(),\n\u001b[0;32m     79\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmonth\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m Days Above 32 (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m: (Grouped_Daily_into_Monthly[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAvg Temp (°C)\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m32\u001b[39m)\u001b[38;5;241m.\u001b[39msum()\n\u001b[0;32m     80\u001b[0m \n\u001b[0;32m     81\u001b[0m     })\n\u001b[0;32m     83\u001b[0m \u001b[38;5;66;03m#Adds this yearly data to original df\u001b[39;00m\n\u001b[0;32m     84\u001b[0m final_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mconcat([final_df, pd\u001b[38;5;241m.\u001b[39mDataFrame([yearly_data])], ignore_index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "\u001b[1;31mTypeError\u001b[0m: '<' not supported between instances of 'SeriesGroupBy' and 'int'"
     ]
    }
   ],
   "source": [
    "recommended_vintages_M1_df, all_vintages_M1_df = Vintage_Dataframe(FINAL_wine_df_filtered_1Bottle_FINAL)\n",
    "vintage_df_M1_final = Final_Vintage_Dataframe(recommended_vintages_M1_df, all_vintages_M1_df, FINAL_wine_df_FINAL, lower_date_bound = 2000, lower_rating_bound  = 3, lower_review_count = 1)\n",
    "\n",
    "FINAL_training_data_Model1_FINAL, Columned_Weather_Data = Training_Data(FINAL_weather_data_FINAL, vintage_df_M1_final)\n",
    "FINAL_training_data_Model1_FINAL.to_csv(os.path.join(final_df_file_path, 'FINAL_training_data_Model1_FINAL.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "recommended_vintages_M2_df, all_vintages_M2_df = Vintage_Dataframe(FINAL_wine_df_filtered_All_Bottles_FINAL)\n",
    "vintage_df_M2_final = Final_Vintage_Dataframe(recommended_vintages_M2_df, all_vintages_M2_df, FINAL_wine_df_FINAL, lower_date_bound = 2000, lower_rating_bound  = 3, lower_review_count = 1)\n",
    "vintage_df_M2_final.to_csv(os.path.join(final_df_file_path, 'vintage_df_M2_final.csv'), index=False)\n",
    "\n",
    "FINAL_training_data_Model2_FINAL = Training_Data_Model2(Columned_Weather_Data, vintage_df_M2_final, FINAL_wine_df_filtered_All_Bottles_FINAL)\n",
    "FINAL_training_data_Model2_FINAL.to_csv(os.path.join(final_df_file_path, 'FINAL_training_data_Model2_FINAL.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An error occurred for URL: https://www.vivino.com/f-thienpont-la-violette-du-manoir/w/6100939 - ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n",
      "An error occurred for URL: https://www.vivino.com/montes-taita-marchigue-vineyard-cabernet-sauvignon/w/1807024 - ('Connection aborted.', ConnectionResetError(10054, 'An existing connection was forcibly closed by the remote host', None, 10054, None))\n"
     ]
    }
   ],
   "source": [
    "recommended_vintages_M2_df, all_vintages_M2_df = Vintage_Dataframe(FINAL_wine_df_filtered_All_Bottles_FINAL)\n",
    "vintage_df_M2_final = Final_Vintage_Dataframe(recommended_vintages_M2_df, all_vintages_M2_df, FINAL_wine_df_FINAL, lower_date_bound = 1900, lower_rating_bound  = 3, lower_review_count = 1)\n",
    "vintage_df_M2_final.to_csv(os.path.join(final_df_file_path, 'vintage_df_M2_final.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vintage_df_M2_final = pd.read_csv(os.path.join(final_df_file_path, 'vintage_df_M2_final.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_training_data_Model2_FINAL = Training_Data_Model2(Columned_Weather_Data, vintage_df_M2_final, FINAL_wine_df_filtered_All_Bottles_FINAL)\n",
    "# FINAL_training_data_Model2_FINAL.to_csv(os.path.join(final_df_file_path, 'FINAL_training_data_Model2_FINAL.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_training_data_Model2_FINAL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
