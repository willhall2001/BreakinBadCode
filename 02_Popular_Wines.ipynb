{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Popular Wines\n",
    "This code initialized the first dataframes, pulling lat/long coordinates, districts and regions for each producer. Then filtering the wines based on internal criterias\n",
    "\n",
    "## Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %pip install requests\n",
    "# %pip install beautifulsoup4\n",
    "# %pip install selenium\n",
    "# %pip install pandas\n",
    "# %pip install geopy\n",
    "# %pip install geopandas\n",
    "# %pip install folium\n",
    "# %pip install openmeteo-requests\n",
    "# %pip install requests-cache retry-requests numpy pandas\n",
    "# %pip install timezonefinder\n",
    "# % pip install seaborn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import OpenCage\n",
    "from folium import Marker\n",
    "from folium import GeoJson\n",
    "from retry_requests import retry\n",
    "from timezonefinder import TimezoneFinder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Breakdown \n",
    "---\n",
    "SQL_Files_to_df\n",
    "- pulls scraped wine data from an SQL file and converts it to a dataframe\n",
    "\n",
    "Lat_Long_Coordinates\n",
    "- takes in a location name and returns a lat long value that is associated with it \n",
    "\n",
    "Wine_DataFrame \n",
    "- creates a dataframe from the initial wine data that contains unique locations and coordinates\n",
    "\n",
    "Regions_and_Districts\n",
    "- takes in global shape files for regions and districts, adds this data to the wine dataframe \n",
    "\n",
    "Popular_Wine_Stats_1Bottle\n",
    "- returns a dataframe with the most popular producer of the most popular winetype in the most popular district and region in the top 8 most popular countries \n",
    "- this dataset will focus on global trends, so a single bottle is used\n",
    "\n",
    "Popular_Wine_Stats_1Bottle_Different\n",
    "- returns a dataframe with the most popular producer of the most popular winetype in the most popular 3 districts and 3 regions in the top 8 most popular countries \n",
    "- this dataset will focus on global trends, so a single bottle is used\n",
    "\n",
    "Popular_Wine_Stats_All_Bottles\n",
    "- returns a dataframe with all the bottles for each of the districts of interest \n",
    "- this dataset will focus on local trends"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SQL_Files_to_df(file_name, host_folder):\n",
    "    \"\"\"\n",
    "    host_folder: name of the host folder with each of the SQL files to read\n",
    "    return: DataFrame of the contents of each sql file \n",
    "    \"\"\"\n",
    "    \n",
    "    # Connect to the SQLite database \n",
    "    conn = sqlite3.connect(os.path.join(host_folder, file_name))\n",
    "\n",
    "    df = pd.read_sql(f'SELECT * FROM red_wines', conn)\n",
    "\n",
    "    df.set_index('id', inplace = True)\n",
    "\n",
    "    df = df.dropna()\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lat_Long_Coordinates(location_name):\n",
    "    \"\"\"\n",
    "    name: takes in a location name\n",
    "    return: returns the lat/long coordinates of the names area\n",
    "    \"\"\"\n",
    "    \n",
    "    #Uses an OpenCage api_key to filter name through geolocator database\n",
    "    geolocator = OpenCage(api_key = 'f339a0ad9adf4d79be69204907140726')\n",
    "    location = geolocator.geocode(location_name) \n",
    "\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    \n",
    "    else:\n",
    "        #To grab further data points, uses Nominatim service to filter name through additional geolocator database\n",
    "        geolocator = Nominatim(user_agent = \"your_unique_user_agent\", timeout = 10)\n",
    "        location = geolocator.geocode(location_name)\n",
    "\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        \n",
    "        else:\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wine_DataFrame(raw_wine_data):\n",
    "    \"\"\"\n",
    "    Raw_Wine_Data: takes in a df of all the wines \n",
    "    return (): returns a data frame where the indices are unique locations, and columns are #instances of each location, and lat/long coordinates\n",
    "\n",
    "    \"\"\"\n",
    "    #Creates a new column with a combination of region + country from the original dataframe\n",
    "    raw_wine_data['Locations'] = raw_wine_data['Region'] + ', ' + raw_wine_data['Country']\n",
    "\n",
    "    #Drops any na values in the location column\n",
    "    raw_wine_data = raw_wine_data.dropna()\n",
    "\n",
    "    #Creates a list of unique locations and number of instances of each unique locations\n",
    "    global_locations = raw_wine_data['Locations'].unique()\n",
    "\n",
    "    #Creates a data frame with 5 columns: Locations, Location_Instances, Latitude, and Longitude\n",
    "    complete_wine_data = pd.DataFrame({\"Locations\" : global_locations,\n",
    "                       'Location_Instances' : raw_wine_data['Locations'].value_counts()\n",
    "                       })\n",
    "    \n",
    "    complete_wine_data[[\"Lat\",\"Long\"]] = complete_wine_data[\"Locations\"].apply(lambda row: pd.Series(Lat_Long_Coordinates(row)))\n",
    "        \n",
    "    #Set index to Locations\n",
    "    complete_wine_data.set_index('Locations', inplace = True)\n",
    "\n",
    "    return complete_wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Regions_and_Districts(wine_data, Location_DataFrame, geojson_host_folder):\n",
    "    \"\"\"\n",
    "    Inputs: The wine data, the intermediate location df created before and a host folder that contains teh geojson data\n",
    "    Output: A modified wine data df with 3 new columns \n",
    "        LatLong_Points: geodataframe geometry point using lat long coords\n",
    "        Regions: polygon geometery of the region the lat long coords are in \n",
    "        District: polygon geometery of the region the lat long coords are in \n",
    "    \"\"\"\n",
    "\n",
    "    wine_data = wine_data.dropna()\n",
    "\n",
    "\n",
    "    #Defines the file names for the regional and district files\n",
    "    regions_filename = 'geoBoundariesCGAZ_ADM1_regions.geojson'\n",
    "    districts_filename = 'geoBoundariesCGAZ_ADM2_districts.geojson'\n",
    "\n",
    "    #Adds the lat long coords to the wine dataframe \n",
    "    Location_df_changed = Location_DataFrame.drop(columns = ['Location_Instances'])\n",
    "    wine_data['Locations'] = wine_data['Region'] + ', ' + wine_data['Country']\n",
    "    wine_data = pd.merge(wine_data, Location_df_changed, on = \"Locations\", how = 'left')\n",
    "    wine_data = wine_data.drop('Region', axis = 1)\n",
    "\n",
    "    #Creates a geodataframe with the coordinates\n",
    "    wine_data_gdf = gpd.GeoDataFrame(wine_data, geometry = gpd.points_from_xy(x = wine_data['Long'], y = wine_data['Lat']), crs = 'EPSG:4326')\n",
    "    wine_data_gdf = wine_data_gdf.rename(columns={'geometry': 'LatLong_Points'})\n",
    "    wine_data_gdf = wine_data_gdf.set_geometry('LatLong_Points')\n",
    "\n",
    "    #Reads the regional and district geodataframes \n",
    "    regions_gdf = gpd.read_file(os.path.join(geojson_host_folder, regions_filename))\n",
    "    districts_gdf = gpd.read_file(os.path.join(geojson_host_folder, districts_filename))\n",
    "    \n",
    "    #Ensure both GeoDataFrames are using the same CRS\n",
    "    regions_gdf = regions_gdf.to_crs(wine_data_gdf.crs)\n",
    "    districts_gdf = districts_gdf.to_crs(wine_data_gdf.crs)\n",
    "\n",
    "    #Joins the wine data df with the regions and districts geodataframs\n",
    "    wine_data_gdf = gpd.sjoin(wine_data_gdf, regions_gdf[['shapeName', 'geometry']], how='left', op='within')\n",
    "    wine_data_gdf = gpd.sjoin(wine_data_gdf, districts_gdf[['shapeName', 'geometry']], how='left', op='within', lsuffix='_region', rsuffix='_district')\n",
    "\n",
    "    #Rename columns for clarity\n",
    "    wine_data_gdf = wine_data_gdf.rename(columns={\n",
    "        'shapeName__region' : 'Region', \n",
    "        'shapeName__district' : 'District',\n",
    "    })\n",
    "\n",
    "    #Drop geodata, wont need to moving forward after locating the regions and districts for each row \n",
    "    wine_data_gdf.drop(['url_idx', 'index_right', 'LatLong_Points', 'index__district'], axis = 1, inplace = True)\n",
    "    \n",
    "    #Set dataframe order, for clarity\n",
    "    wine_data_gdf = wine_data_gdf[['WineType','Producer', 'Locations', 'Rating',\n",
    "                                    'Num_Ratings', 'Price', 'Country', 'Region', 'District',\n",
    "                                    'Lat', 'Long', 'URL']]\n",
    "    \n",
    "    return wine_data_gdf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Popular_Wine_Stats_1Bottle(wine_data_final, number_of_districts = 1):\n",
    "    \"\"\"\n",
    "    Input: wine_data_final which should contain a dataframe that has counties, regions, wintetype, and producers\n",
    "    Output: A dataframe containing the top countries, \n",
    "            region within those countries, top 5 districts within that region,\n",
    "            top winetype within that district and top producer of that wine\n",
    "    \"\"\"\n",
    "\n",
    "    #Drop an unnecessary column\n",
    "    if 'Unnamed: 0' in wine_data_final.columns:\n",
    "        wine_data_final = wine_data_final.drop(columns = ['Unnamed: 0'])\n",
    "        \n",
    "    #Creates a simple name for easy use while referencing \n",
    "    df = wine_data_final.copy()\n",
    "\n",
    "    #Get total bottle counts by country and filter out countries with bottle counts more than the 75th percentile\n",
    "    total_bottles_country = df['Country'].value_counts()\n",
    "    top_countries = total_bottles_country[total_bottles_country > total_bottles_country.quantile(0.75)]\n",
    "\n",
    "    #Filter the df to make winetypes uniform \n",
    "    popular_wine_types = ['château margaux', 'cabernet sauvignon', 'pinot noir', 'zinfandel', 'syrah', \n",
    "                            'pinot gris', 'sauvignon blanc', 'chardonnay', 'baco noir', 'bordeaux',\n",
    "                            'malbec', 'chardonnay', 'pinot grigio', 'merlot', 'sangiovese', 'shiraz',\n",
    "                            'cabernet franc', 'muscat', 'grenache', 'sangiovese'  ]\n",
    "    \n",
    "    #Sets all the winetypes to be lower \n",
    "    df['WineType'] = df['WineType'].str.lower()\n",
    "\n",
    "    #Filters through each of the winetypes, then changes the df winetype name if the wine type is in the row string \n",
    "    for winetype in popular_wine_types:\n",
    "\n",
    "        df['WineType']  = df['WineType'].apply(lambda row: next((winetype for winetype in popular_wine_types if winetype in row), row))\n",
    "\n",
    "    #Creates dataframe for output\n",
    "    popular_wines = pd.DataFrame()\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries and pulls the top regions and the amount of bottles associated with them\n",
    "    for country in top_countries.index:\n",
    "\n",
    "        #Checks if region is in top countries, then grabs the top region \n",
    "        filter_country_df = df[df['Country'] == country]\n",
    "\n",
    "        top_region = filter_country_df['Region'].value_counts().idxmax()\n",
    "        top_region_count = filter_country_df['Region'].value_counts().max()\n",
    "\n",
    "        popular_wines = pd.concat([popular_wines, pd.DataFrame([{'Top Country': country, 'Country Count': int(top_countries[country]), 'Top Region': top_region, 'Region Count': top_region_count}])])     \n",
    "        popular_wines.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries and regions within those countries and pulls the top districts and the amount of bottles associated with them\n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "        #Checks if winetype is in top region, then grabs the top winetype \n",
    "        filter_region_df = df[df['Region'] == row['Top Region']]\n",
    "        top_district_count = filter_region_df['District'].value_counts().head(number_of_districts)\n",
    "\n",
    "        #Goes through each of the top 5 districts and adds the district name and count for a given country and region\n",
    "        for district, count in top_district_count.items():\n",
    "            if count > 0: \n",
    "                new_rows.append({'index' : index, 'Top District' : district, 'District Count' : count})\n",
    "        \n",
    "    #Adds the district data to the popular_wines dataframe \n",
    "    district_type = pd.DataFrame(new_rows)\n",
    "    district_type.set_index('index', inplace = True)\n",
    "\n",
    "    #Merge district dataframe to the popular wines dateframe\n",
    "    popular_wines = pd.merge(popular_wines, district_type, left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    # Goes through the top counties and gets top district and region within those countries and pulls the top winetype and the amount of bottles associated with them\n",
    "\n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "        #Filter the dataframe based on region and district\n",
    "        filtered_district_df = df[(df['Region'] == row['Top Region']) & (df['District'] == row['Top District'])]\n",
    "\n",
    "        #Checks if winetype is in top region, then grabs the top winetype \n",
    "        top_winetype = filtered_district_df['WineType'].value_counts().idxmax()\n",
    "        top_winetype_count = int((filtered_district_df['WineType'].value_counts().max()))\n",
    "        \n",
    "        new_rows.append({'Top WineType' : top_winetype, 'WineType Count' : top_winetype_count})\n",
    "    \n",
    "    #Adds the winetype data to the popular_wines dataframe \n",
    "    wine_type = pd.DataFrame(new_rows)\n",
    "    popular_wines['Top WineType'] = wine_type['Top WineType'].values\n",
    "    popular_wines['WineType Count'] = wine_type['WineType Count'].values\n",
    "    popular_wines.reset_index(inplace = True)\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries, regions within those countries, and top winetype within that region pulling the top producer\n",
    "    \n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "                #Checks if producer is in top region, district, and produces top winetype, then grabs the top producers\n",
    "                top_producers = df[(df['WineType'] == row['Top WineType']) & (df['District'] == row['Top District']) & (df['Region'] == row['Top Region'])]\n",
    "\n",
    "                #Grabs the quantiles for the number of ratings, then filters out the data below the lowest 25% \n",
    "                #The mean is then found for the ratings based on the producer \n",
    "                Num_of_Ratings_Quantile = np.quantile(df['Num_Ratings'], [0.25, 0.5, 0.75])\n",
    "                top_producer = top_producers[top_producers['Num_Ratings'] >  Num_of_Ratings_Quantile[0]].groupby(by = 'Producer')['Rating'].mean().sort_values(ascending = False)\n",
    "\n",
    "                #Ensure top_producer has data\n",
    "                if not top_producer.empty:  \n",
    "                    new_rows.append({'Producer': top_producer.index[0], 'Average Rating': top_producer.iloc[0]})\n",
    "                else:\n",
    "                    new_rows.append({'Producer': 'No Producer Found', 'Average Rating': None})\n",
    "\n",
    "    producer_rating = pd.DataFrame(new_rows)\n",
    "    popular_wines['Producer'] = producer_rating['Producer'].values\n",
    "    popular_wines['Average Rating'] = producer_rating['Average Rating'].values\n",
    "    popular_wines.reset_index(inplace = True)\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    #Add price, URL, and lat/long coords for the outputed points\n",
    "    df_urllatlong = pd.DataFrame()\n",
    "    df_urllatlong[['Price', 'Producer','Lat', 'Long', 'URL']] = df.drop_duplicates(subset = 'Producer')[['Price', 'Producer',  'Lat', 'Long', 'URL']]\n",
    "    final_popular_wines = pd.merge(popular_wines, df_urllatlong, on = 'Producer')\n",
    "\n",
    "    #Drop any rows with no producer\n",
    "    final_popular_wines = final_popular_wines[final_popular_wines['Producer'] != 'No Producer Found']\n",
    "   \n",
    "    return final_popular_wines.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Popular_Wine_Stats_1Bottle_Different(wine_data_final, number_of_regions = 1, number_of_districts = 1):\n",
    "    \"\"\"\n",
    "    Input: wine_data_final which should contain a dataframe that has counties, regions, wintetype, and producers\n",
    "    Output: A dataframe containing the top countries, \n",
    "            X number of regions within those countries, X number of districts within that region,\n",
    "            top winetype within that district and top producer of that wine\n",
    "    \"\"\"\n",
    "\n",
    "    #Drop an unnecessary column\n",
    "    if 'Unnamed: 0' in wine_data_final.columns:\n",
    "        wine_data_final = wine_data_final.drop(columns = ['Unnamed: 0'])\n",
    "        \n",
    "    #Creates a simple name for easy use while referencing \n",
    "    df = wine_data_final.copy()\n",
    "\n",
    "    #Get total bottle counts by country and filter out countries with bottle counts more than the 75th percentile\n",
    "    total_bottles_country = df['Country'].value_counts()\n",
    "    top_countries = total_bottles_country[total_bottles_country > total_bottles_country.quantile(0.75)]\n",
    "\n",
    "    #Filter the df to make winetypes uniform \n",
    "    popular_wine_types = ['château margaux', 'cabernet sauvignon', 'pinot noir', 'zinfandel', 'syrah', \n",
    "                            'pinot gris', 'sauvignon blanc', 'chardonnay', 'baco noir', 'bordeaux',\n",
    "                            'malbec', 'chardonnay', 'pinot grigio', 'merlot', 'sangiovese', 'shiraz',\n",
    "                            'cabernet franc', 'muscat', 'grenache', 'sangiovese'  ]\n",
    "    \n",
    "    #Sets all the winetypes to be lower \n",
    "    df['WineType'] = df['WineType'].str.lower()\n",
    "\n",
    "    #Filters through each of the winetypes, then changes the df winetype name if the wine type is in the row string \n",
    "    for winetype in popular_wine_types:\n",
    "\n",
    "        df['WineType']  = df['WineType'].apply(lambda row: next((winetype for winetype in popular_wine_types if winetype in row), row))\n",
    "\n",
    "    #Creates dataframe for output\n",
    "    popular_wines = pd.DataFrame()\n",
    "    \n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries and pulls the top regions and the amount of bottles associated with them\n",
    "    \n",
    "    new_rows = []\n",
    "    for country in top_countries.index:\n",
    "\n",
    "        #Adds country data\n",
    "        popular_wines = pd.concat([popular_wines, pd.DataFrame([{'Top Country': country, 'Country Count': int(top_countries[country])}])])     \n",
    "        popular_wines.reset_index(drop = True, inplace = True)\n",
    "\n",
    "        #Checks if region is in top countries, then grabs the top regions \n",
    "        filter_country_df = df[df['Country'] == country]\n",
    "        top_region_count = filter_country_df['Region'].value_counts().head(number_of_regions)\n",
    "\n",
    "        #Goes through each of the top regions and adds the region name and count for a given country\n",
    "        for region, count in top_region_count.items():\n",
    "            if count > 0: \n",
    "                new_rows.append({'Top Country' : country, 'Top Region' : region, 'Region Count' : count})\n",
    "\n",
    "\n",
    "    #Adds the region data to the popular_wines dataframe \n",
    "    region_type = pd.DataFrame(new_rows)\n",
    "\n",
    "    #Merge region dataframe to the popular wines dateframe\n",
    "    popular_wines = pd.merge(popular_wines, region_type, on = 'Top Country', how = 'left')\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries and regions within those countries and pulls the top districts and the amount of bottles associated with them\n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "        #Checks if winetype is in top region, then grabs the top winetype \n",
    "        filter_region_df = df[df['Region'] == row['Top Region']]\n",
    "        top_district_count = filter_region_df['District'].value_counts().head(number_of_districts)\n",
    "\n",
    "        #Goes through each of the top 5 districts and adds the district name and count for a given country and region\n",
    "        for district, count in top_district_count.items():\n",
    "            if count > 0: \n",
    "                new_rows.append({'index' : index, 'Top District' : district, 'District Count' : count})\n",
    "        \n",
    "    #Adds the district data to the popular_wines dataframe \n",
    "    district_type = pd.DataFrame(new_rows)\n",
    "    district_type.set_index('index', inplace = True)\n",
    "\n",
    "    #Merge district dataframe to the popular wines dateframe\n",
    "    popular_wines = pd.merge(popular_wines, district_type, left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    # Goes through the top counties and gets top district and region within those countries and pulls the top winetype and the amount of bottles associated with them\n",
    "\n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "        #Filter the dataframe based on region and district\n",
    "        filtered_district_df = df[(df['Region'] == row['Top Region']) & (df['District'] == row['Top District'])]\n",
    "\n",
    "        #Checks if winetype is in top region, then grabs the top winetype \n",
    "        top_winetype = filtered_district_df['WineType'].value_counts().idxmax()\n",
    "        top_winetype_count = int((filtered_district_df['WineType'].value_counts().max()))\n",
    "        \n",
    "        new_rows.append({'Top WineType' : top_winetype, 'WineType Count' : top_winetype_count})\n",
    "    \n",
    "    #Adds the winetype data to the popular_wines dataframe \n",
    "    wine_type = pd.DataFrame(new_rows)\n",
    "    popular_wines['Top WineType'] = wine_type['Top WineType'].values\n",
    "    popular_wines['WineType Count'] = wine_type['WineType Count'].values\n",
    "    popular_wines.reset_index(inplace = True)\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries, regions within those countries, and top winetype within that region \n",
    "    #Pulls the producers of that winetype, and takes a mean of them, returning the top 5 from that mean\n",
    "    \n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "                #Grabs tops producers from top winetype, district, region and country\n",
    "                top_producers = df[(df['WineType'] == row['Top WineType']) & (df['District'] == row['Top District']) & (df['Region'] == row['Top Region'])]\n",
    "\n",
    "                #To prevent quantiles from being taken on single or \n",
    "                if len(top_producers) > 8: \n",
    "\n",
    "                    #Removes bottom 25 and top 75 from price\n",
    "                    price_75th_quantile  = np.percentile(top_producers['Price'], 75)\n",
    "                    price_25th_quantile = np.percentile(top_producers['Price'], 25)\n",
    "                    top_producers_filt = top_producers[top_producers['Price'].between(price_25th_quantile ,price_75th_quantile)]\n",
    "\n",
    "                    #Grabs new top quantile for price and number of ratings \n",
    "                    price_75th_quantile_filtered = np.percentile(top_producers_filt['Price'], 75)\n",
    "                    num_Ratings_25th_quantile_filtered = np.percentile(top_producers_filt['Num_Ratings'], 25)\n",
    "\n",
    "                    #Filters dataframe by the limits\n",
    "                    final_producer_data = top_producers_filt[(top_producers_filt['Price'] > price_75th_quantile_filtered) &\n",
    "                                                            (top_producers_filt['Num_Ratings'] > num_Ratings_25th_quantile_filtered)\n",
    "                                                            ].groupby('Producer')['Rating'].mean().sort_values(ascending = False)\n",
    "                    \n",
    "                else:\n",
    "                    final_producer_data = top_producers_filt.groupby('Producer')['Rating'].mean().sort_values(ascending = False)\n",
    "\n",
    "                #Ensure top_producer has data\n",
    "                if not final_producer_data.empty:  \n",
    "                    new_rows.append({'Producer': final_producer_data.index[0], 'Average Rating': final_producer_data.iloc[0]})\n",
    "                else:\n",
    "                    new_rows.append({'Producer': 'No Producer Found', 'Average Rating': None})\n",
    "\n",
    "    producer_rating = pd.DataFrame(new_rows)\n",
    "\n",
    "    popular_wines['Producer'] = producer_rating['Producer'].values\n",
    "    popular_wines['Average Rating'] = producer_rating['Average Rating'].values\n",
    "    popular_wines.reset_index(inplace = True)\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    #Add price, URL, and lat/long coords for the outputed points\n",
    "    df_urllatlong = pd.DataFrame()\n",
    "    df_urllatlong[['Price', 'Producer','Lat', 'Long', 'URL']] = df.drop_duplicates(subset = 'Producer')[['Price', 'Producer',  'Lat', 'Long', 'URL']]\n",
    "    final_popular_wines = pd.merge(popular_wines, df_urllatlong, on = 'Producer')\n",
    "\n",
    "    #Drop any rows with no producer and filter bottle so only 10+ bottle counts are condisered\n",
    "    final_popular_wines = final_popular_wines[final_popular_wines['Producer'] != 'No Producer Found']\n",
    "    final_popular_wines = final_popular_wines[final_popular_wines['WineType Count'] > 10]\n",
    "   \n",
    "    return final_popular_wines.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Popular_Wine_Stats_All_Bottles(wine_data_final, wine_data_1bottle, number_of_districts):\n",
    "    \"\"\"\n",
    "    Input: wine_data_final which should contain a dataframe that has counties, regions, wintetype, and producers\n",
    "    Output: A dataframe containing the top countries, \n",
    "            region within those countries, top 5 districts within that region,\n",
    "            top winetype within that district and top producer of that wine\n",
    "    \"\"\"\n",
    "    #Drop an unnecessary column\n",
    "    if 'Unnamed: 0' in wine_data_final.columns:\n",
    "        wine_data_final = wine_data_final.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "    #Creates a simple name for easy use while referencing \n",
    "    df = wine_data_final.copy()\n",
    "\n",
    "    #Get total bottle counts by country and filter out countries with bottle counts more than the 75th percentile\n",
    "    total_bottles_country = df['Country'].value_counts()\n",
    "    top_countries = total_bottles_country[total_bottles_country > total_bottles_country.quantile(0.75)]\n",
    "\n",
    "    #Filter the df to make winetypes uniform \n",
    "    popular_wine_types = ['château margaux', 'cabernet sauvignon', 'pinot noir', 'zinfandel', 'syrah', \n",
    "                            'pinot gris', 'sauvignon blanc', 'chardonnay', 'baco noir', 'bordeaux',\n",
    "                            'malbec', 'chardonnay', 'pinot grigio', 'merlot', 'sangiovese', 'shiraz',\n",
    "                            'cabernet franc', 'muscat', 'grenache', 'sangiovese'  ]\n",
    "    \n",
    "    #Sets all the winetypes to be lower \n",
    "    df['WineType'] = df['WineType'].str.lower()\n",
    "\n",
    "    #Filters through each of the winetypes, then changes the df winetype name if the wine type is in the row string \n",
    "    for winetype in popular_wine_types:\n",
    "\n",
    "        df['WineType']  = df['WineType'].apply(lambda row: next((winetype for winetype in popular_wine_types if winetype in row), row))\n",
    "\n",
    "    #Creates dataframe for output\n",
    "    popular_wines = pd.DataFrame()\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries and pulls the top regions and the amount of bottles associated with them\n",
    "    for country in top_countries.index:\n",
    "\n",
    "        #Checks if region is in top countries, then grabs the top region \n",
    "        filter_country_df = df[df['Country'] == country]\n",
    "\n",
    "        top_region = filter_country_df['Region'].value_counts().idxmax()\n",
    "        top_region_count = filter_country_df['Region'].value_counts().max()\n",
    "\n",
    "        popular_wines = pd.concat([popular_wines, pd.DataFrame([{'Top Country': country, 'Country Count': int(top_countries[country]), 'Top Region': top_region, 'Region Count': top_region_count}])])     \n",
    "        popular_wines.reset_index(drop = True, inplace = True)\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries and regions within those countries and pulls the top districts and the amount of bottles associated with them\n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "        #Checks if winetype is in top region, then grabs the top winetype \n",
    "        filter_region_df = df[df['Region'] == row['Top Region']]\n",
    "        top_district_count = filter_region_df['District'].value_counts().nlargest(number_of_districts)\n",
    "\n",
    "        #Goes through each of the top 5 districts and adds the district name and count for a given country and region\n",
    "        for district, count in top_district_count.items():\n",
    "            new_rows.append({'index' : index, 'Top District' : district})\n",
    "        \n",
    "    #Adds the district data to the popular_wines dataframe \n",
    "    district_type = pd.DataFrame(new_rows)\n",
    "    district_type.set_index('index', inplace = True)\n",
    "\n",
    "    #Merge district dataframe to the popular wines dateframe\n",
    "    popular_wines = pd.merge(popular_wines, district_type, left_index = True, right_index = True, how = 'left')\n",
    "\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "    #Goes through the top countries, regions within those countries, and top district within that region \n",
    "    #Pulls the producers of each winetype, and takes a mean of them, returning the top 5 from that mean\n",
    "    \n",
    "    new_rows = []\n",
    "    for index, row in popular_wines.iterrows():\n",
    "\n",
    "                #Checks if producer is in top region, district, and produces top winetype, then grabs the top producers\n",
    "                top_producers_filtered = df[(df['District'] == row['Top District']) & (df['Region'] == row['Top Region'])]\n",
    "\n",
    "                #Filter the producers, so one rating per producer\n",
    "                top_producers = top_producers_filtered.groupby(by = ['WineType','Producer'])['Rating'].mean()\n",
    "\n",
    "                #Go through each winetype and get the producer and rating \n",
    "                for (winetype, producer), rating in top_producers.items():\n",
    "                \n",
    "                    new_rows.append({'District' : row['Top District'],\n",
    "                                     'WineType' : winetype,\n",
    "                                     'Producer' : producer, \n",
    "                                     'Rating' : rating\n",
    "                                     })\n",
    "\n",
    "    district_data = pd.DataFrame(new_rows)\n",
    "    popular_wines = pd.merge(popular_wines, district_data, left_on = 'Top District', right_on = 'District')\n",
    "    popular_wines.reset_index(inplace = True)\n",
    "    popular_wines = popular_wines.drop(columns = ['District'])\n",
    "    #------------------------------------------------------------------------------------------------------------#\n",
    "\n",
    "    #Add price, URL, and lat/long coords for the outputed points\n",
    "    df_url = pd.DataFrame()\n",
    "    df_url[['Price', 'Producer', 'URL']] = df.drop_duplicates(subset = 'Producer')[['Price', 'Producer', 'URL']]\n",
    "    final_popular_wines = pd.merge(popular_wines, df_url, on = 'Producer')\n",
    "    \n",
    "    df_latlong = pd.DataFrame()\n",
    "    df_latlong[['Top District', 'Lat', 'Long']] =  wine_data_1bottle[['Top District', 'Lat', 'Long']]\n",
    "    final_popular_wines = pd.merge(final_popular_wines, df_latlong, on = 'Top District')\n",
    "   \n",
    "    return final_popular_wines.iloc[:, 2:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code Running Section\n",
    "\n",
    "Change file_path to fit local repository\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_path = ''\n",
    "final_df_file_path = 'Final_DataFrames'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m red_wines \u001b[38;5;241m=\u001b[39m SQL_Files_to_df(\u001b[38;5;124mr\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mWine_Raw_Data\u001b[39m\u001b[38;5;124m\\\u001b[39m\u001b[38;5;124mred_wines_final.db\u001b[39m\u001b[38;5;124m'\u001b[39m, file_path )\n\u001b[1;32m----> 2\u001b[0m location_df \u001b[38;5;241m=\u001b[39m Wine_DataFrame(red_wines)\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mWine_DataFrame\u001b[1;34m(raw_wine_data)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#Creates a data frame with 5 columns: Locations, Location_Instances, Latitude, and Longitude\u001b[39;00m\n\u001b[0;32m     17\u001b[0m complete_wine_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m\"\u001b[39m : global_locations,\n\u001b[0;32m     18\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation_Instances\u001b[39m\u001b[38;5;124m'\u001b[39m : raw_wine_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m     19\u001b[0m                    })\n\u001b[1;32m---> 21\u001b[0m complete_wine_data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLong\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m complete_wine_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: pd\u001b[38;5;241m.\u001b[39mSeries(Lat_Long_Coordinates(row)))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Set index to Locations\u001b[39;00m\n\u001b[0;32m     24\u001b[0m complete_wine_data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\pandas\\core\\series.py:4764\u001b[0m, in \u001b[0;36mSeries.apply\u001b[1;34m(self, func, convert_dtype, args, by_row, **kwargs)\u001b[0m\n\u001b[0;32m   4629\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mapply\u001b[39m(\n\u001b[0;32m   4630\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4631\u001b[0m     func: AggFuncType,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4636\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[0;32m   4637\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame \u001b[38;5;241m|\u001b[39m Series:\n\u001b[0;32m   4638\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m   4639\u001b[0m \u001b[38;5;124;03m    Invoke function on values of Series.\u001b[39;00m\n\u001b[0;32m   4640\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   4755\u001b[0m \u001b[38;5;124;03m    dtype: float64\u001b[39;00m\n\u001b[0;32m   4756\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m   4757\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m SeriesApply(\n\u001b[0;32m   4758\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m   4759\u001b[0m         func,\n\u001b[0;32m   4760\u001b[0m         convert_dtype\u001b[38;5;241m=\u001b[39mconvert_dtype,\n\u001b[0;32m   4761\u001b[0m         by_row\u001b[38;5;241m=\u001b[39mby_row,\n\u001b[0;32m   4762\u001b[0m         args\u001b[38;5;241m=\u001b[39margs,\n\u001b[0;32m   4763\u001b[0m         kwargs\u001b[38;5;241m=\u001b[39mkwargs,\n\u001b[1;32m-> 4764\u001b[0m     )\u001b[38;5;241m.\u001b[39mapply()\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1209\u001b[0m, in \u001b[0;36mSeriesApply.apply\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1206\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_compat()\n\u001b[0;32m   1208\u001b[0m \u001b[38;5;66;03m# self.func is Callable\u001b[39;00m\n\u001b[1;32m-> 1209\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapply_standard()\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\pandas\\core\\apply.py:1289\u001b[0m, in \u001b[0;36mSeriesApply.apply_standard\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1283\u001b[0m \u001b[38;5;66;03m# row-wise access\u001b[39;00m\n\u001b[0;32m   1284\u001b[0m \u001b[38;5;66;03m# apply doesn't have a `na_action` keyword and for backward compat reasons\u001b[39;00m\n\u001b[0;32m   1285\u001b[0m \u001b[38;5;66;03m# we need to give `na_action=\"ignore\"` for categorical data.\u001b[39;00m\n\u001b[0;32m   1286\u001b[0m \u001b[38;5;66;03m# TODO: remove the `na_action=\"ignore\"` when that default has been changed in\u001b[39;00m\n\u001b[0;32m   1287\u001b[0m \u001b[38;5;66;03m#  Categorical (GH51645).\u001b[39;00m\n\u001b[0;32m   1288\u001b[0m action \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mignore\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(obj\u001b[38;5;241m.\u001b[39mdtype, CategoricalDtype) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m-> 1289\u001b[0m mapped \u001b[38;5;241m=\u001b[39m obj\u001b[38;5;241m.\u001b[39m_map_values(\n\u001b[0;32m   1290\u001b[0m     mapper\u001b[38;5;241m=\u001b[39mcurried, na_action\u001b[38;5;241m=\u001b[39maction, convert\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconvert_dtype\n\u001b[0;32m   1291\u001b[0m )\n\u001b[0;32m   1293\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(mapped) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(mapped[\u001b[38;5;241m0\u001b[39m], ABCSeries):\n\u001b[0;32m   1294\u001b[0m     \u001b[38;5;66;03m# GH#43986 Need to do list(mapped) in order to get treated as nested\u001b[39;00m\n\u001b[0;32m   1295\u001b[0m     \u001b[38;5;66;03m#  See also GH#25959 regarding EA support\u001b[39;00m\n\u001b[0;32m   1296\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m obj\u001b[38;5;241m.\u001b[39m_constructor_expanddim(\u001b[38;5;28mlist\u001b[39m(mapped), index\u001b[38;5;241m=\u001b[39mobj\u001b[38;5;241m.\u001b[39mindex)\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\pandas\\core\\base.py:921\u001b[0m, in \u001b[0;36mIndexOpsMixin._map_values\u001b[1;34m(self, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m    918\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(arr, ExtensionArray):\n\u001b[0;32m    919\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m arr\u001b[38;5;241m.\u001b[39mmap(mapper, na_action\u001b[38;5;241m=\u001b[39mna_action)\n\u001b[1;32m--> 921\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m algorithms\u001b[38;5;241m.\u001b[39mmap_array(arr, mapper, na_action\u001b[38;5;241m=\u001b[39mna_action, convert\u001b[38;5;241m=\u001b[39mconvert)\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\pandas\\core\\algorithms.py:1814\u001b[0m, in \u001b[0;36mmap_array\u001b[1;34m(arr, mapper, na_action, convert)\u001b[0m\n\u001b[0;32m   1812\u001b[0m values \u001b[38;5;241m=\u001b[39m arr\u001b[38;5;241m.\u001b[39mastype(\u001b[38;5;28mobject\u001b[39m, copy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m   1813\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m na_action \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m-> 1814\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer(values, mapper, convert\u001b[38;5;241m=\u001b[39mconvert)\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1816\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m lib\u001b[38;5;241m.\u001b[39mmap_infer_mask(\n\u001b[0;32m   1817\u001b[0m         values, mapper, mask\u001b[38;5;241m=\u001b[39misna(values)\u001b[38;5;241m.\u001b[39mview(np\u001b[38;5;241m.\u001b[39muint8), convert\u001b[38;5;241m=\u001b[39mconvert\n\u001b[0;32m   1818\u001b[0m     )\n",
      "File \u001b[1;32mlib.pyx:2926\u001b[0m, in \u001b[0;36mpandas._libs.lib.map_infer\u001b[1;34m()\u001b[0m\n",
      "Cell \u001b[1;32mIn[5], line 21\u001b[0m, in \u001b[0;36mWine_DataFrame.<locals>.<lambda>\u001b[1;34m(row)\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[38;5;66;03m#Creates a data frame with 5 columns: Locations, Location_Instances, Latitude, and Longitude\u001b[39;00m\n\u001b[0;32m     17\u001b[0m complete_wine_data \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m\"\u001b[39m : global_locations,\n\u001b[0;32m     18\u001b[0m                    \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocation_Instances\u001b[39m\u001b[38;5;124m'\u001b[39m : raw_wine_data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mvalue_counts()\n\u001b[0;32m     19\u001b[0m                    })\n\u001b[1;32m---> 21\u001b[0m complete_wine_data[[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLat\u001b[39m\u001b[38;5;124m\"\u001b[39m,\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLong\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m complete_wine_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m row: pd\u001b[38;5;241m.\u001b[39mSeries(Lat_Long_Coordinates(row)))\n\u001b[0;32m     23\u001b[0m \u001b[38;5;66;03m#Set index to Locations\u001b[39;00m\n\u001b[0;32m     24\u001b[0m complete_wine_data\u001b[38;5;241m.\u001b[39mset_index(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLocations\u001b[39m\u001b[38;5;124m'\u001b[39m, inplace \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m)\n",
      "Cell \u001b[1;32mIn[4], line 8\u001b[0m, in \u001b[0;36mLat_Long_Coordinates\u001b[1;34m(location_name)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      3\u001b[0m \u001b[38;5;124;03mname: takes in a location name\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;124;03mreturn: returns the lat/long coordinates of the names area\u001b[39;00m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;66;03m#Uses an OpenCage api_key to filter name through geolocator database\u001b[39;00m\n\u001b[1;32m----> 8\u001b[0m geolocator \u001b[38;5;241m=\u001b[39m OpenCage(api_key \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mf339a0ad9adf4d79be69204907140726\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m      9\u001b[0m location \u001b[38;5;241m=\u001b[39m geolocator\u001b[38;5;241m.\u001b[39mgeocode(location_name) \n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m location:\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\opencage.py:68\u001b[0m, in \u001b[0;36mOpenCage.__init__\u001b[1;34m(self, api_key, domain, scheme, timeout, proxies, user_agent, ssl_context, adapter_factory)\u001b[0m\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     27\u001b[0m         \u001b[38;5;28mself\u001b[39m,\n\u001b[0;32m     28\u001b[0m         api_key,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     36\u001b[0m         adapter_factory\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m     37\u001b[0m ):\n\u001b[0;32m     38\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m     39\u001b[0m \n\u001b[0;32m     40\u001b[0m \u001b[38;5;124;03m    :param str api_key: The API key required by OpenCageData\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m        .. versionadded:: 2.0\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[1;32m---> 68\u001b[0m     \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(\n\u001b[0;32m     69\u001b[0m         scheme\u001b[38;5;241m=\u001b[39mscheme,\n\u001b[0;32m     70\u001b[0m         timeout\u001b[38;5;241m=\u001b[39mtimeout,\n\u001b[0;32m     71\u001b[0m         proxies\u001b[38;5;241m=\u001b[39mproxies,\n\u001b[0;32m     72\u001b[0m         user_agent\u001b[38;5;241m=\u001b[39muser_agent,\n\u001b[0;32m     73\u001b[0m         ssl_context\u001b[38;5;241m=\u001b[39mssl_context,\n\u001b[0;32m     74\u001b[0m         adapter_factory\u001b[38;5;241m=\u001b[39madapter_factory,\n\u001b[0;32m     75\u001b[0m     )\n\u001b[0;32m     77\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mapi_key \u001b[38;5;241m=\u001b[39m api_key\n\u001b[0;32m     78\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdomain \u001b[38;5;241m=\u001b[39m domain\u001b[38;5;241m.\u001b[39mstrip(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\geopy\\geocoders\\base.py:247\u001b[0m, in \u001b[0;36mGeocoder.__init__\u001b[1;34m(self, scheme, timeout, proxies, user_agent, ssl_context, adapter_factory)\u001b[0m\n\u001b[0;32m    245\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m adapter_factory \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    246\u001b[0m     adapter_factory \u001b[38;5;241m=\u001b[39m options\u001b[38;5;241m.\u001b[39mdefault_adapter_factory\n\u001b[1;32m--> 247\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter \u001b[38;5;241m=\u001b[39m adapter_factory(\n\u001b[0;32m    248\u001b[0m     proxies\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mproxies,\n\u001b[0;32m    249\u001b[0m     ssl_context\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mssl_context,\n\u001b[0;32m    250\u001b[0m )\n\u001b[0;32m    251\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39madapter, BaseSyncAdapter):\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m__run_async \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\site-packages\\geopy\\adapters.py:418\u001b[0m, in \u001b[0;36mRequestsAdapter.__init__\u001b[1;34m(self, proxies, ssl_context, pool_connections, pool_maxsize, max_retries, pool_block)\u001b[0m\n\u001b[0;32m    403\u001b[0m proxies \u001b[38;5;241m=\u001b[39m _normalize_proxies(proxies)\n\u001b[0;32m    404\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m ssl_context \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    405\u001b[0m     \u001b[38;5;66;03m# By default requests uses CA bundle from `certifi` package.\u001b[39;00m\n\u001b[0;32m    406\u001b[0m     \u001b[38;5;66;03m# This is typically overridden with the `REQUESTS_CA_BUNDLE`\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    416\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    417\u001b[0m     \u001b[38;5;66;03m# See also https://github.com/geopy/geopy/issues/546\u001b[39;00m\n\u001b[1;32m--> 418\u001b[0m     ssl_context \u001b[38;5;241m=\u001b[39m ssl\u001b[38;5;241m.\u001b[39mcreate_default_context()\n\u001b[0;32m    419\u001b[0m \u001b[38;5;28msuper\u001b[39m()\u001b[38;5;241m.\u001b[39m\u001b[38;5;21m__init__\u001b[39m(proxies\u001b[38;5;241m=\u001b[39mproxies, ssl_context\u001b[38;5;241m=\u001b[39mssl_context)\n\u001b[0;32m    421\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msession \u001b[38;5;241m=\u001b[39m requests\u001b[38;5;241m.\u001b[39mSession()\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\ssl.py:775\u001b[0m, in \u001b[0;36mcreate_default_context\u001b[1;34m(purpose, cafile, capath, cadata)\u001b[0m\n\u001b[0;32m    770\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_verify_locations(cafile, capath, cadata)\n\u001b[0;32m    771\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m context\u001b[38;5;241m.\u001b[39mverify_mode \u001b[38;5;241m!=\u001b[39m CERT_NONE:\n\u001b[0;32m    772\u001b[0m     \u001b[38;5;66;03m# no explicit cafile, capath or cadata but the verify mode is\u001b[39;00m\n\u001b[0;32m    773\u001b[0m     \u001b[38;5;66;03m# CERT_OPTIONAL or CERT_REQUIRED. Let's try to load default system\u001b[39;00m\n\u001b[0;32m    774\u001b[0m     \u001b[38;5;66;03m# root CA certificates for the given purpose. This may fail silently.\u001b[39;00m\n\u001b[1;32m--> 775\u001b[0m     context\u001b[38;5;241m.\u001b[39mload_default_certs(purpose)\n\u001b[0;32m    776\u001b[0m \u001b[38;5;66;03m# OpenSSL 1.1.1 keylog file\u001b[39;00m\n\u001b[0;32m    777\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(context, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mkeylog_filename\u001b[39m\u001b[38;5;124m'\u001b[39m):\n",
      "File \u001b[1;32mc:\\Users\\fwhal\\anaconda3\\Lib\\ssl.py:597\u001b[0m, in \u001b[0;36mSSLContext.load_default_certs\u001b[1;34m(self, purpose)\u001b[0m\n\u001b[0;32m    595\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m storename \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_windows_cert_stores:\n\u001b[0;32m    596\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_load_windows_store_certs(storename, purpose)\n\u001b[1;32m--> 597\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mset_default_verify_paths()\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "red_wines = SQL_Files_to_df(r'Wine_Raw_Data\\red_wines_final.db', file_path )\n",
    "location_df = Wine_DataFrame(red_wines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Long processing time, have saved previous output to csv, load from this\n",
    "# FINAL_wine_df_FINAL = Regions_and_Districts(red_wines, location_df, os.path.join(r'C:\\Users\\fwhal\\Downloads\\CME528\\Project', 'GeoJsonFiles'))\n",
    "# FINAL_wine_df_FINAL.to_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_FINAL.csv'), index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Data For a Single Bottle\n",
    "- filtered the bottles based solely on popularity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL_wine_df_FINAL = pd.read_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_FINAL.csv'))\n",
    "\n",
    "# FINAL_wine_df_filtered_1Bottle_FINAL = Popular_Wine_Stats_1Bottle(FINAL_wine_df_FINAL, number_of_districts = 6)\n",
    "# FINAL_wine_df_filtered_1Bottle_FINAL.to_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_filtered_1Bottle_FINAL.csv'), index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Data For a Different Set of Single Bottle\n",
    "- filtered the bottles differently, adding in more regions and filtering out more extreme values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_wine_df_FINAL = pd.read_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_FINAL.csv'))\n",
    "\n",
    "FINAL_wine_df_filtered_different_1Bottle_FINAL = Popular_Wine_Stats_1Bottle_Different(FINAL_wine_df_FINAL, number_of_regions = 3, number_of_districts = 3)\n",
    "FINAL_wine_df_filtered_different_1Bottle_FINAL.to_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_filtered_different_1Bottle_FINAL.csv'), index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wine Data For a All Bottles\n",
    "- Grabs all the bottles for a district"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FINAL_wine_df_filtered_All_Bottles_FINAL = Popular_Wine_Stats_All_Bottles(FINAL_wine_df_FINAL, FINAL_wine_df_filtered_1Bottle_FINAL, number_of_districts = 5)\n",
    "# FINAL_wine_df_filtered_All_Bottles_FINAL.to_csv(os.path.join(final_df_file_path, 'FINAL_wine_df_filtered_All_Bottles_FINAL.csv'), index = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Function Breakdown \n",
    "---\n",
    "Plotting_Unique_Locations\n",
    "- plots all the wine locations from producer using the Wine_DataFrame function "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Plotting_Unique_Locations(DataFrame):\n",
    "    \"\"\"\n",
    "    df: A dataframe with columns including Location_Instances, and lat/long coordinates\n",
    "    return: a global map of where wines are located from \n",
    "    \"\"\"\n",
    "    #Drop any NaN from the data\n",
    "    DataFrame = DataFrame.dropna()\n",
    "\n",
    "    #Converts DataFrame into a GeoDataFrame\n",
    "    Global_Areas = gpd.GeoDataFrame(DataFrame, geometry = gpd.points_from_xy(x = DataFrame['Long'], y = DataFrame['Lat']), crs = 'EPSG:4326')\n",
    "\n",
    "    # Create map centered around Toronto \n",
    "    map_1 = folium.Map(location = [43.6426, -79.3871], \n",
    "                    tiles = 'cartodbpositron', \n",
    "                    zoom_start = 2)\n",
    "        \n",
    "    # Plot each buffer area and show the map \n",
    "    GeoJson(Global_Areas).add_to(map_1)\n",
    "\n",
    "    for idx, row in Global_Areas.iterrows():\n",
    "\n",
    "        #Creates a base size for each location, that grows with each instance recorded\n",
    "        radius = 6500 + row['Location_Instances'] * 50\n",
    "\n",
    "        folium.Circle(\n",
    "            location = [row['Lat'], row['Long']],\n",
    "            radius = radius,  \n",
    "            color = 'blue',\n",
    "            fill = True,\n",
    "            fill_color = 'blue',\n",
    "            fill_opacity = 0.3,\n",
    "            popup = folium.Popup(f\"Location: {row.name}\", parse_html = True)\n",
    "        ).add_to(map_1)\n",
    "\n",
    "    return map_1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code Running Section"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'location_df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[17], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Plotting_Unique_Locations(location_df)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'location_df' is not defined"
     ]
    }
   ],
   "source": [
    "Plotting_Unique_Locations(location_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
