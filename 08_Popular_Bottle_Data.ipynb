{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import requests\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "import folium\n",
    "import openmeteo_requests\n",
    "import requests_cache\n",
    "import sqlite3\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import json\n",
    "import re\n",
    "from bs4 import BeautifulSoup\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from geopy.geocoders import Nominatim\n",
    "from geopy.geocoders import OpenCage\n",
    "from folium import Marker\n",
    "from folium import GeoJson\n",
    "from retry_requests import retry\n",
    "from timezonefinder import TimezoneFinder "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "Function Breakdown\n",
    "---\n",
    "\n",
    "Lat_Long_Coordinates\n",
    "- takes in a location name and returns a lat long value that is associated with it \n",
    "\n",
    "Wine_DataFrame \n",
    "- creates a dataframe from the initial wine data that contains unique locations and coordinates\n",
    "\n",
    "Top_Bottles \n",
    "- Takes in the dataframes of each of the top bottles and returns 1 dataframe where they are all merged together, with lat/long coords\n",
    "\n",
    "Weather_Data_DataFrame\n",
    "- pulls the weather data on a hourly scale for a specific lat and long, from a start date to an end data\n",
    "\n",
    "Parsed_Weather_Data\n",
    "- converts hourly data to daily data and returns desired metrics about each day \n",
    "\n",
    "All_Weather_Data\n",
    "- parses through all the popular wines returned from the Popular_Wine_Stats\n",
    "- final dataframe containes daily weather data on each wine in a large dataframe based on popular producers\n",
    "\n",
    "Training_Data\n",
    "- converts output dataframe from All_Weather_Data into a dataframe indexed across producers and years \n",
    "- the columns are monthly averages based on the daily data\n",
    "- adds in the rating and price data for the specific producer of a specific wine for a specific year "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Lat_Long_Coordinates(location_name):\n",
    "    \"\"\"\n",
    "    name: takes in a location name\n",
    "    return: returns the lat/long coordinates of the names area\n",
    "    \"\"\"\n",
    "    \n",
    "    #Uses an OpenCage api_key to filter name through geolocator database\n",
    "    geolocator = OpenCage(api_key = 'f339a0ad9adf4d79be69204907140726')\n",
    "    location = geolocator.geocode(location_name) \n",
    "\n",
    "    if location:\n",
    "        return location.latitude, location.longitude\n",
    "    \n",
    "    else:\n",
    "        #To grab further data points, uses Nominatim service to filter name through additional geolocator database\n",
    "        geolocator = Nominatim(user_agent = \"your_unique_user_agent\", timeout = 10)\n",
    "        location = geolocator.geocode(location_name)\n",
    "\n",
    "        if location:\n",
    "            return location.latitude, location.longitude\n",
    "        \n",
    "        else:\n",
    "            return None, None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Wine_DataFrame(raw_wine_data):\n",
    "    \"\"\"\n",
    "    Raw_Wine_Data: takes in a df of all the wines \n",
    "    return (): returns a data frame where the indices are unique locations, and columns are #instances of each location, and lat/long coordinates\n",
    "\n",
    "    \"\"\"\n",
    "    #Creates a new column with a combination of region + country from the original dataframe\n",
    "    raw_wine_data['Locations'] = raw_wine_data['Region'] + ', ' + raw_wine_data['Country']\n",
    "\n",
    "    #Creates a list of unique locations and number of instances of each unique locations\n",
    "    global_locations = raw_wine_data['Locations'].unique()\n",
    "\n",
    "    #Creates a data frame with 5 columns: Locations, Location_Instances, Latitude, and Longitude\n",
    "    complete_wine_data = pd.DataFrame({\"Locations\" : global_locations,\n",
    "                       'Location_Instances' : raw_wine_data['Locations'].value_counts()\n",
    "                       })\n",
    "    \n",
    "    complete_wine_data[[\"Lat\",\"Long\"]] = complete_wine_data[\"Locations\"].apply(lambda row: pd.Series(Lat_Long_Coordinates(row)))\n",
    "        \n",
    "    #Set index to Locations\n",
    "    complete_wine_data.set_index('Locations', inplace = True)\n",
    "\n",
    "    return complete_wine_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Top_Bottles(Dry_df, Medium_df, Sweet_df, Best_df):\n",
    "    \"\"\"\n",
    "    Input: Takes in each of the top wines\n",
    "    Output: A dataframe with the top wines added together and each of the lat/long coords found for each\n",
    "    \"\"\"\n",
    "    #Initialize dataframe\n",
    "    df = pd.DataFrame()\n",
    "\n",
    "    #Go through each of the dataframes and add them together\n",
    "    for wine_list in [Dry_df, Medium_df, Sweet_df, Best_df]:\n",
    "        \n",
    "        df = pd.concat([df, wine_list],  axis = 0)\n",
    "\n",
    "    #Run the wine_dataframe function\n",
    "    df = Wine_DataFrame(df)\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Weather_Data_DataFrame (lat, long, start_date, end_date):\n",
    "    \"\"\" \n",
    "    Input: lat/long coordinates of where weather data should be pulled, the respective timezone, and the start and end dates for the desired location\n",
    "    Output: 2 dataframes, the first which includes hourly data on temp, precipitation, humiduty, cloud cover and soil data\n",
    "        the second includes daily data on the amount of sun recieved each day \n",
    "    \"\"\"\n",
    "    # Setup the Open-Meteo API client with cache and retry on error\n",
    "    cache_session = requests_cache.CachedSession('.cache', expire_after = -1)\n",
    "    retry_session = retry(cache_session, retries = 1, backoff_factor = 0.2)\n",
    "    openmeteo = openmeteo_requests.Client(session = retry_session)\n",
    "\n",
    "    # Make sure all required weather variables are listed here\n",
    "    # The order of variables in hourly or daily is important to assign them correctly below\n",
    "    url = \"https://archive-api.open-meteo.com/v1/archive\"\n",
    "    params = {\n",
    "        \"latitude\": lat,\n",
    "        \"longitude\": long,\n",
    "        \"start_date\": f\"{start_date}-01-01\",\n",
    "        \"end_date\": f\"{end_date}-12-31\",\n",
    "        \"hourly\": [\"temperature_2m\", \"relative_humidity_2m\", \"precipitation\", \"rain\", \"snowfall\", \"cloud_cover\", \"wind_speed_10m\", \"soil_temperature_0_to_7cm\", \"soil_moisture_0_to_7cm\"],\n",
    "        \"daily\": [\"sunrise\", \"sunset\", \"daylight_duration\"],\n",
    "    }\n",
    "    responses = openmeteo.weather_api(url, params=params)\n",
    "\n",
    "    # Process first location. Add a for-loop for multiple locations or weather models\n",
    "    response = responses[0]\n",
    "\n",
    "    # Process hourly data. The order of variables needs to be the same as requested.\n",
    "    hourly = response.Hourly()\n",
    "    hourly_temperature_2m = hourly.Variables(0).ValuesAsNumpy()\n",
    "    hourly_relative_humidity_2m = hourly.Variables(1).ValuesAsNumpy()\n",
    "    hourly_rain = hourly.Variables(3).ValuesAsNumpy()\n",
    "    hourly_snowfall = hourly.Variables(4).ValuesAsNumpy()\n",
    "    hourly_cloud_cover = hourly.Variables(5).ValuesAsNumpy()\n",
    "    hourly_wind_speed_10m = hourly.Variables(6).ValuesAsNumpy()\n",
    "    hourly_soil_temperature_0_to_7cm = hourly.Variables(7).ValuesAsNumpy()\n",
    "    hourly_soil_moisture_0_to_7cm = hourly.Variables(8).ValuesAsNumpy()\n",
    "\n",
    "    hourly_data = {\"date\": pd.date_range(\n",
    "        start = pd.to_datetime(hourly.Time(), unit = \"s\", utc = True),\n",
    "        end = pd.to_datetime(hourly.TimeEnd(), unit = \"s\", utc = True),\n",
    "        freq = pd.Timedelta(seconds = hourly.Interval()),\n",
    "        inclusive = \"left\"\n",
    "    )}\n",
    "    hourly_data[\"temperature_2m\"] = hourly_temperature_2m\n",
    "    hourly_data[\"relative_humidity_2m\"] = hourly_relative_humidity_2m\n",
    "    hourly_data[\"rain\"] = hourly_rain\n",
    "    hourly_data[\"snowfall\"] = hourly_snowfall\n",
    "    hourly_data[\"cloud_cover\"] = hourly_cloud_cover\n",
    "    hourly_data[\"wind_speed_10m\"] = hourly_wind_speed_10m\n",
    "    hourly_data[\"soil_temperature_0_to_7cm\"] = hourly_soil_temperature_0_to_7cm\n",
    "    hourly_data[\"soil_moisture_0_to_7cm\"] = hourly_soil_moisture_0_to_7cm\n",
    "\n",
    "    hourly_dataframe = pd.DataFrame(data = hourly_data)\n",
    "    hourly_dataframe.set_index(\"date\", inplace=True)\n",
    "\n",
    "    # Process daily data. The order of variables needs to be the same as requested.\n",
    "    daily = response.Daily()\n",
    "    daily_daylight_duration = daily.Variables(2).ValuesAsNumpy()\n",
    "\n",
    "    daily_data = {\"date\": pd.date_range(\n",
    "        start = pd.to_datetime(daily.Time(), unit = \"s\", utc = True),\n",
    "        end = pd.to_datetime(daily.TimeEnd(), unit = \"s\", utc = True),\n",
    "        freq = pd.Timedelta(seconds = daily.Interval()),\n",
    "        inclusive = \"left\"\n",
    "    )}\n",
    "\n",
    "    daily_data[\"daylight_duration\"] = daily_daylight_duration\n",
    "\n",
    "    daily_dataframe = pd.DataFrame(data = daily_data)\n",
    "    daily_dataframe.set_index(\"date\", inplace=True)\n",
    "\n",
    "    \n",
    "    return hourly_dataframe, daily_dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Parsed_Weather_Data(Weather_Hourly_Data, Weather_Daily_Data):\n",
    "    \"\"\"\n",
    "    Input: two data frames with hourly and daily data for various weather metrics\n",
    "    Ouput: a new data frame with daily data that was grouped from the hourly and daily \n",
    "        input data frames, with new metrics which will be used for future comparison \n",
    "    \"\"\"\n",
    "    \n",
    "    #Most data has almost none or no datapoints that are NaN, however just in case, we will drop them \n",
    "    Weather_Hourly_Data = Weather_Hourly_Data.dropna()\n",
    "    Weather_Daily_Data = Weather_Daily_Data.dropna()\n",
    "\n",
    "    #Group the hourly data into daily \n",
    "    Grouped_Hourly_into_Daily = Weather_Hourly_Data.groupby(Weather_Hourly_Data.index.floor('D'))    \n",
    "\n",
    "    #Create the DataFrame with all the data required\n",
    "    daily_df = pd.DataFrame({\n",
    "\n",
    "        'Date' : Grouped_Hourly_into_Daily.size().index,\n",
    "        'Max Temp (°C)' : Grouped_Hourly_into_Daily['temperature_2m'].max(),\n",
    "        'Min Temp (°C)' : Grouped_Hourly_into_Daily['temperature_2m'].min(),\n",
    "        'Avg Temp (°C)' : Grouped_Hourly_into_Daily['temperature_2m'].mean(),\n",
    "        'Max Relative Humidity' : Grouped_Hourly_into_Daily['relative_humidity_2m'].max(),\n",
    "        'Min Relative Humidity' : Grouped_Hourly_into_Daily['relative_humidity_2m'].min(),\n",
    "        'Avg Relative Humidity' : Grouped_Hourly_into_Daily['relative_humidity_2m'].mean(),\n",
    "        'Cumulative Precip (Rain + Snow)(mm)' : Grouped_Hourly_into_Daily['rain'].sum() + Grouped_Hourly_into_Daily['snowfall'].sum(),\n",
    "        'Cumulative Rain (mm)' : Grouped_Hourly_into_Daily['rain'].sum(),\n",
    "        'Cumulative Snow (mm)' : Grouped_Hourly_into_Daily['snowfall'].sum(),\n",
    "        'Avg Cloud Cover (%)' : Grouped_Hourly_into_Daily['cloud_cover'].mean(),\n",
    "        'Max Wind Speed (Km/h)' : Grouped_Hourly_into_Daily['wind_speed_10m'].max(),\n",
    "        'Min Wind Speed (Km/h)' : Grouped_Hourly_into_Daily['wind_speed_10m'].min(),\n",
    "        'Avg Wind Speed (Km/h)' : Grouped_Hourly_into_Daily['wind_speed_10m'].mean(),\n",
    "\n",
    "    })\n",
    "\n",
    "    daily_df.reset_index(drop=True, inplace=True)\n",
    "    \n",
    "    #Ensures the dataframes are the same size and adds the daylight duration column\n",
    "    daily_df = daily_df.iloc[:len(Weather_Daily_Data)]\n",
    "    daily_df['Daylight Hours'] = Weather_Daily_Data['daylight_duration'].values / (60*60)\n",
    "\n",
    "    return daily_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def All_Weather_Data(wine_dataframe, start_data, end_date):\n",
    "    \"\"\"\n",
    "    Input: takes in the datframe of wine locations, start and end dates, and the saved folder location\n",
    "    Output: a dataframe that containes all the weather data for each specific location between the start and end dates \n",
    "        Output data is all saved to the specified folder location\n",
    "    \"\"\"\n",
    "\n",
    "    #Drop an unnecessary column\n",
    "    if 'Unnamed: 0' in wine_dataframe.columns:\n",
    "        wine_dataframe = wine_dataframe.drop(columns = ['Unnamed: 0'])\n",
    "\n",
    "    #Defines the initial empty dataframe\n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    #Creates a batch size and delay for future use\n",
    "    delay = 60 \n",
    "    max_retries = 5\n",
    "\n",
    "    # print(wine_dataframe)\n",
    "    \n",
    "    #Iterate through each of the rows to add the respective data to a master file \n",
    "    for index, row in wine_dataframe.iterrows():\n",
    "        \n",
    "        #Creates a while loop, so if the process fails the iteration will wait then rerun from the same row\n",
    "        success = False\n",
    "        retries = 0 \n",
    "\n",
    "        while not success and retries < max_retries:\n",
    "\n",
    "            #Hitting the weather website API call limit was an issue so a Try and Execpt block added to iterate and wait if call limit hit\n",
    "            try:\n",
    "                #Grab weather data using Weather_Data_DataFrame and Parsed_Weather_Data functions\n",
    "                weather_data_hourly, weather_data_daily  = Weather_Data_DataFrame(row['Lat'], row['Long'], start_data, end_date)\n",
    "                weather_data_daily_final = Parsed_Weather_Data(weather_data_hourly, weather_data_daily)\n",
    "                \n",
    "                #Grab all the important columns and add them to the weather dataframe\n",
    "                weather_data_daily_final[['Top Country', 'Top Region', 'Top District', 'Top WineType', 'Producer', 'Price', 'Lat', 'Long']] = row[['Top Country', 'Top Region', 'Top District', 'Top WineType', 'Producer', 'Price', 'Lat', 'Long']]\n",
    "                \n",
    "                #Reorder column so producer at front\n",
    "                weather_data_daily_final.insert(0,'Producer',weather_data_daily_final.pop('Producer'))\n",
    "                weather_data_daily_final.insert(1,'Top WineType',weather_data_daily_final.pop('Top WineType'))\n",
    "\n",
    "                #Add each single data set to the final data set \n",
    "                weather_data_daily_final.set_index('Date', inplace=True)\n",
    "                final_df = pd.concat([final_df, weather_data_daily_final])\n",
    "\n",
    "                #Add a delay to prevent API call limit\n",
    "                time.sleep(delay) \n",
    "                success = True \n",
    "\n",
    "            except: \n",
    "                time.sleep(delay) \n",
    "                retries += 1\n",
    "\n",
    "        \n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Training_Data(weather_df, wine_df):\n",
    "    \"\"\"\n",
    "    Input: Weather dataframe indexed on the daily scale,\n",
    "        Vintage dataframe which has yearly bottles from the same producer and wine type\n",
    "    Output: Weather dataframe indexed based on a single row for a producer and year \n",
    "        columns will be monthly min, max or average for the respective data per year\n",
    "    \"\"\"\n",
    "    #Weather_df.index = pd.to_datetime(weather_df.index)\n",
    "    producers = weather_df['Producer'].unique()\n",
    "\n",
    "    #Initializes a dataframe \n",
    "    final_df = pd.DataFrame()\n",
    "\n",
    "    #Check to see if date is the index\n",
    "    if type(weather_df.index[0]) == int:\n",
    "\n",
    "        weather_df = weather_df.set_index('Date') \n",
    "\n",
    "    #Filter the wine_df to make winetypes uniform \n",
    "    popular_wine_types = ['château margaux', 'cabernet sauvignon', 'pinot noir', 'zinfandel', 'syrah', \n",
    "                            'pinot gris', 'sauvignon blanc', 'chardonnay', 'baco noir', 'bordeaux',\n",
    "                            'malbec', 'chardonnay', 'pinot grigio', 'merlot', 'sangiovese', 'shiraz',\n",
    "                            'cabernet franc', 'muscat', 'grenache', 'sangiovese'  ]\n",
    "    \n",
    "    #Sets all the winetypes to be lower \n",
    "    wine_df['WineType'] = wine_df['WineType'].str.lower()\n",
    "\n",
    "    #Filters through each of the winetypes, then changes the df winetype name if the wine type is in the row string \n",
    "    for winetype in popular_wine_types:\n",
    "\n",
    "        wine_df['WineType']  = wine_df['WineType'].apply(lambda row: next((winetype for winetype in popular_wine_types if winetype in row), row))\n",
    "\n",
    "    #Create a column for the year and produce all the unique years\n",
    "    weather_df.index = pd.to_datetime(weather_df.index)\n",
    "    weather_df['Year'] = weather_df.index.year\n",
    "    unique_years = weather_df['Year'].unique()\n",
    "\n",
    "    #Find all the unique months\n",
    "    weather_df['Month'] = weather_df.index.month\n",
    "    unique_months = weather_df['Month'].unique()\n",
    "\n",
    "    #Gives key for the month names \n",
    "    month_names = {1 : 'January', 2 : 'February', 3 : 'March', 4 : 'April', 5 : 'May', \n",
    "                                  6 : 'June', 7 : 'July', 8 : 'August', 9 : 'September', 10 : 'October', 11 : 'November',\n",
    "                                  12 : 'December'}\n",
    "\n",
    "    for producer in producers:\n",
    "\n",
    "        #Filter the data based on the producer\n",
    "        producer_df = weather_df[weather_df['Producer'] == producer]\n",
    "\n",
    "        #Iterate over each unique year\n",
    "        for year in unique_years:\n",
    "            \n",
    "            #Filter the data for the specific year\n",
    "            yearly_df = producer_df[producer_df['Year'] == year]\n",
    "\n",
    "            #Creates initial data\n",
    "            yearly_data = {'Producer' : producer, 'Year' : year}\n",
    "\n",
    "            #Ierate over each unique month\n",
    "            for month in unique_months: \n",
    "\n",
    "                #Filter the data for the specific month\n",
    "                monthly_df = yearly_df[yearly_df['Month'] == month]\n",
    "\n",
    "                #Group by month\n",
    "                Grouped_Daily_into_Monthly = monthly_df.groupby(monthly_df.index.to_period('M'))\n",
    "\n",
    "                #Change month number to month name\n",
    "                month = month_names[month]\n",
    "\n",
    "                yearly_data.update({\n",
    "                    \n",
    "                    'WineType' : Grouped_Daily_into_Monthly['Top WineType'].first()[0],\n",
    "                    'District' : Grouped_Daily_into_Monthly['Top District'].first()[0],\n",
    "                    f'{month} Max Temp (°C)' : Grouped_Daily_into_Monthly['Max Temp (°C)'].max().iloc[0],\n",
    "                    f'{month} Min Temp (°C)' : Grouped_Daily_into_Monthly['Min Temp (°C)'].min().iloc[0],\n",
    "                    f'{month} Avg Temp (°C)' : Grouped_Daily_into_Monthly['Avg Temp (°C)'].mean().iloc[0],\n",
    "                    f'{month} Max Relative Humidity' : Grouped_Daily_into_Monthly['Max Relative Humidity'].max().iloc[0],\n",
    "                    f'{month} Min Relative Humidity' : Grouped_Daily_into_Monthly['Min Relative Humidity'].min().iloc[0],\n",
    "                    f'{month} Avg Relative Humidity' : Grouped_Daily_into_Monthly['Max Relative Humidity'].mean().iloc[0],\n",
    "                    f'{month} Cumulative Rain (mm)' : Grouped_Daily_into_Monthly['Cumulative Rain (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Snow (mm)' : Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Precip (mm)' : Grouped_Daily_into_Monthly['Cumulative Rain (mm)'].sum().iloc[0] + Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Cumulative Snow (mm)' : Grouped_Daily_into_Monthly['Cumulative Snow (mm)'].sum().iloc[0],\n",
    "                    f'{month} Avg Cloud Cover (%)' : Grouped_Daily_into_Monthly['Avg Cloud Cover (%)'].mean().iloc[0],\n",
    "                    f'{month} Max Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Max Wind Speed (Km/h)'].max().iloc[0],\n",
    "                    f'{month} Min Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Min Wind Speed (Km/h)'].min().iloc[0],\n",
    "                    f'{month} Avg Wind Speed (Km/h)' : Grouped_Daily_into_Monthly['Avg Wind Speed (Km/h)'].mean().iloc[0],\n",
    "                    f'{month} Avg Daylight Hours' : Grouped_Daily_into_Monthly['Daylight Hours'].mean().iloc[0], \n",
    "                    f'{month} Days Below 0 (°C)': (monthly_df['Avg Temp (°C)'] <= 0).sum(),\n",
    "                    f'{month} Days Above 32 (°C)': (monthly_df['Avg Temp (°C)'] > 32).sum()\n",
    "\n",
    "                })\n",
    "            \n",
    "            #Adds this yearly data to original df\n",
    "            final_df = pd.concat([final_df, pd.DataFrame([yearly_data])], ignore_index=True)\n",
    "    \n",
    "    #Add a producer/year column for future merging and reset index\n",
    "    final_df = final_df.reset_index()\n",
    "    final_df['Producer_WineType_Year'] = final_df['Producer'] + '/' + final_df['WineType'] + '/' + final_df['Year'].astype(str)\n",
    "    final_df['Producer_WineType_Year'] = final_df['Producer_WineType_Year'].str.lower()\n",
    "\n",
    "    weather_df_columns = final_df.drop(columns = ['index'])\n",
    "    print(final_df)\n",
    "\n",
    "    #Format wine_df \n",
    "    wine_df['Producer_WineType_Year'] = wine_df['Producer'] + '/' + wine_df['WineType'] + '/' + wine_df['year'].astype(str)\n",
    "    wine_df['Producer_WineType_Year'] = wine_df['Producer_WineType_Year'].str.lower()\n",
    "\n",
    "    #Combine the two dataframes     \n",
    "    final_df = pd.merge(final_df, wine_df, on = 'Producer_WineType_Year', how = 'left')\n",
    "    \n",
    "    #Modify the dataframe for easier viewing\n",
    "    final_df = final_df.drop(columns = ['index', 'year', 'Producer_y', 'WineType_y', 'has_valid_ratings', 'Producer_WineType_Year'])\n",
    "    \n",
    "    final_df.insert(0, 'Producer', final_df.pop('Producer_x'))\n",
    "    final_df.insert(1, 'WineType', final_df.pop('WineType_x'))\n",
    "    final_df.insert(2, 'District', final_df.pop('District'))\n",
    "    final_df.insert(3, 'Region', final_df.pop('Region'))\n",
    "    final_df.insert(4, 'Country', final_df.pop('Country'))\n",
    "    final_df.insert(5, 'Year', final_df.pop('Year'))\n",
    "    final_df.insert(5, 'Ratings_Average', final_df.pop('ratings_average'))\n",
    "\n",
    "    #Drop all the rows that have NAN in the ratings average column \n",
    "    final_df = final_df.dropna(subset = ['Ratings_Average'])\n",
    "\n",
    "    return final_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Code Running Section\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "wines_file_path = r'C:\\Users\\fwhal\\Downloads\\CME528\\Project\\Repo-2\\BreakinBadCode\\Final_Wines_Of_Interest'\n",
    "final_df_file_path = r'C:\\Users\\fwhal\\Downloads\\CME528\\Project\\Repo-2\\BreakinBadCode\\Final_DataFrames'\n",
    "\n",
    "\n",
    "Dry_Wines = pd.read_csv(os.path.join(wines_file_path, 'Best_Drywines.csv'))\n",
    "Medium_Wines = pd.read_csv(os.path.join(wines_file_path, 'Best_Medium_Drywines.csv'))\n",
    "Sweet_Wines = pd.read_csv(os.path.join(wines_file_path, 'Best_Sweetwines.csv'))\n",
    "Best_Wines = pd.read_csv(os.path.join(wines_file_path, 'Best_Wines.csv'))\n",
    "\n",
    "FINAL_weather_data_FINAL = pd.read_csv(os.path.join(final_df_file_path, 'FINAL_weather_data_FINAL.csv'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "wine_df = Top_Bottles(Dry_Wines, Medium_Wines, Sweet_Wines, Best_Wines)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FINAL_weather_data_FINAL = All_Weather_Data(wine_df, 2000, 2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Top_Wines_df = Training_Data(FINAL_weather_data_FINAL, wine_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
